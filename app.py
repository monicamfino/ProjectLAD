import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import time
from sklearn.linear_model import Ridge, Lasso, LinearRegression
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.metrics import mean_squared_error, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from sklearn import tree
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier


# Configura√ß√£o da p√°gina
st.set_page_config(page_title="BugsBunny - Detec√ß√£o de Fraude üí≥", layout="wide")

# Estilizando o app
st.markdown("""
    <style>
        .big-font { font-size:30px !important; font-weight: bold; }
        .stApp { background-color: #f5f5f5; }
    </style>
""", unsafe_allow_html=True)


# Carregar os dados
@st.cache_data
def load_data():
    time.sleep(2)
    df = pd.read_csv("creditcard.csv")
    df = df.dropna()
    df["Hour"] = (df["Time"] // 3600) % 24

    # Criar novas features
    df["Rolling_Mean_Amount"] = df["Amount"].rolling(window=5).mean()
    df["Std_Amount"] = df["Amount"].rolling(window=5).std()
    df["Delta_Amount"] = df["Amount"].diff()
    df["Amount_Category"] = pd.cut(df["Amount"], bins=[0, 10, 50, 100, 500, 5000, np.inf],
                                   labels=["Very Low", "Low", "Medium", "High", "Very High", "Extreme"])
    df["Time_Diff"] = df["Time"].diff()
    df["Transacao_Noturna"] = df["Hour"].apply(lambda x: 1 if x < 6 else 0)
    df["Num_Transacoes_1h"] = df.groupby("Hour")["Time"].transform("count")
    df["Freq_Valor_Transacao"] = df.groupby("Amount")["Amount"].transform("count")
    df["Delta_Media_Valor"] = df["Amount"] - df["Rolling_Mean_Amount"]

    np.random.seed(42)
    df["Region"] = np.random.choice(["Norte", "Sul", "Leste", "Oeste", "Centro"], size=len(df))
    return df


df = load_data()

# Criar Sidebar (Menu lateral)
st.sidebar.image("https://cdn-icons-png.flaticon.com/512/1041/1041916.png", width=100)
st.sidebar.title("üê∞ BugsBunny Analytics")
st.sidebar.write("Solu√ß√µes Inteligentes para a Detec√ß√£o de Fraudes")
page = st.sidebar.radio("Navega√ß√£o", [
    "üè† Vis√£o Geral",
    "üìä An√°lise de Fraudes",
    "üìà Estat√≠sticas",
    "üìÇ Relat√≥rios e Configura√ß√µes",
    "üß≠ Dados",
    "ü§ñ Machine Learning"
])

# üìå P√°gina Inicial - Vis√£o Geral
if page == "üè† Vis√£o Geral":
    st.markdown('<p class="big-font">üîç Vis√£o Geral - Detec√ß√£o de Fraude</p>', unsafe_allow_html=True)

    # üè¢ Sobre a Plataforma
    st.subheader("üíº Sobre o BugsBunny Analytics")
    st.write("""
    A nossa miss√£o √© ajudar empresas a detectarem fraudes financeiras com intelig√™ncia artificial e an√°lise de dados.
    Oferecemos solu√ß√µes para monitoriza√ß√£o, preven√ß√£o e identifica√ß√£o de atividades suspeitas.
    """)

    # üìú Tipos Comuns de Fraude
    st.subheader("üìú Tipos Comuns de Fraude")
    fraud_types = pd.DataFrame({
        "Tipo de Fraude": ["Fraude em Cart√£o de Cr√©dito", "Phishing", "Roubo de Identidade", "Transa√ß√µes Falsificadas"],
        "Descri√ß√£o": [
            "Utiliza√ß√£o n√£o autorizada do cart√£o para compras.",
            "Enganar utilizadores para fornecerem informa√ß√µes sens√≠veis.",
            "Falsifica√ß√£o de identidade para acesso financeiro il√≠cito.",
            "Manipula√ß√£o ou falsifica√ß√£o de transa√ß√µes banc√°rias."
        ]
    })
    st.table(fraud_types)

    # üìä Estat√≠sticas Gerais
    total_transacoes = len(df)
    transacoes_fraudulentas = df["Class"].sum()
    taxa_fraude = (transacoes_fraudulentas / total_transacoes) * 100

    col1, col2, col3 = st.columns(3)
    col1.metric("üí≥ Total de Transa√ß√µes", f"{total_transacoes:,}")
    col2.metric("‚ö† Transa√ß√µes Fraudulentas", f"{transacoes_fraudulentas:,}")
    col3.metric("üìâ Taxa de Fraude", f"{taxa_fraude:.2f} %")

    # üõ†Ô∏è Vari√°veis Utilizadas no Modelo e no CSV
    st.subheader("üõ†Ô∏è Vari√°veis Utilizadas no Modelo e no CSV")
    variaveis_combinadas = pd.DataFrame({
        "Vari√°vel": [
            "Time", "V1-V28", "Amount", "Class",
            "Hour", "Rolling_Mean_Amount", "Std_Amount", "Delta_Amount",
            "Amount_Category", "Time_Diff", "Transacao_Noturna",
            "Num_Transacoes_1h", "Freq_Valor_Transacao", "Delta_Media_Valor", "Region"
        ],
        "Descri√ß√£o": [
            "Tempo decorrido desde a primeira transa√ß√£o no dataset.",
            "Vari√°veis anonimizadas resultantes de PCA (28 componentes principais).",
            "Montante da transa√ß√£o.",
            "Classe da transa√ß√£o (0: Leg√≠tima, 1: Fraudulenta).",
            "Hora do dia em que a transa√ß√£o ocorreu.",
            "M√©dia m√≥vel do valor da transa√ß√£o (janela de 5 transa√ß√µes).",
            "Desvio padr√£o do valor da transa√ß√£o (janela de 5 transa√ß√µes).",
            "Diferen√ßa entre o valor atual e o valor anterior da transa√ß√£o.",
            "Categoria do valor da transa√ß√£o (ex.: Muito Baixo, Baixo, M√©dio, etc.).",
            "Diferen√ßa de tempo entre transa√ß√µes consecutivas.",
            "Indica se a transa√ß√£o ocorreu durante a noite (1: Sim, 0: N√£o).",
            "N√∫mero de transa√ß√µes realizadas na mesma hora.",
            "Frequ√™ncia de transa√ß√µes com o mesmo valor.",
            "Diferen√ßa entre o valor da transa√ß√£o e a m√©dia m√≥vel.",
            "Regi√£o geogr√°fica associada √† transa√ß√£o."
        ]
    })
    st.table(variaveis_combinadas)

    # üõ°Ô∏è Como Prevenir Fraudes?
    st.subheader("üõ°Ô∏è Como Prevenir Fraudes?")
    st.write("""
    A preven√ß√£o de fraudes envolve um conjunto de boas pr√°ticas e tecnologias que ajudam a proteger empresas e consumidores. 
    Aqui est√£o algumas recomenda√ß√µes essenciais:
    """)

    fraud_prevention = pd.DataFrame({
        "Tipo de Fraude": ["Fraude em Cart√£o de Cr√©dito", "Phishing", "Roubo de Identidade", "Transa√ß√µes Falsificadas"],
        "Medidas Preventivas": [
            "Ativar alertas de transa√ß√£o, usar autentica√ß√£o multifator e monitoramento cont√≠nuo.",
            "Nunca compartilhar dados pessoais, verificar remetentes suspeitos e utilizar autentica√ß√£o em dois fatores.",
            "Utilizar verifica√ß√£o biom√©trica, n√£o reutilizar senhas e ativar bloqueios autom√°ticos.",
            "Implementar monitoramento de transa√ß√µes em tempo real e an√°lises de comportamento."
        ]
    })
    st.table(fraud_prevention)

    # üí° Tecnologias e Estrat√©gias para Preven√ß√£o
    st.subheader("üí° Tecnologias e Estrat√©gias para Preven√ß√£o de Fraudes")
    st.write("""
    As empresas podem adotar as seguintes tecnologias para refor√ßar a seguran√ßa:
    - **Machine Learning & IA**: Modelos que analisam padr√µes e detectam anomalias.
    - **Autentica√ß√£o Multifator (MFA)**: Verifica√ß√£o em duas etapas para acessos financeiros.
    - **Monitoramento em Tempo Real**: Identifica√ß√£o de transa√ß√µes suspeitas √† medida que ocorrem.
    - **Criptografia Avan√ßada**: Prote√ß√£o de dados sens√≠veis contra acessos n√£o autorizados.
    - **An√°lises de Comportamento**: Identifica√ß√£o de padr√µes incomuns de uso do sistema.
    """)

# P√°gina 2: An√°lise de Fraudes
elif page == "üìä An√°lise de Fraudes":
    st.markdown('<p class="big-font">üìä An√°lise de Fraudes</p>', unsafe_allow_html=True)
    fraud = df[df["Class"] == 1]
    legit = df[df["Class"] == 0]

    # üî• Filtros Interativos
    st.subheader("üéØ Filtros de An√°lise")
    hora_selecionada = st.slider("Selecione um intervalo de hor√°rio", 0, 23, (0, 23))
    regiao_selecionada = st.multiselect("Filtrar por regi√£o", df["Region"].unique(), default=df["Region"].unique())

    fraude_filtrada = fraud[
        (fraud["Hour"].between(hora_selecionada[0], hora_selecionada[1])) &
        (fraud["Region"].isin(regiao_selecionada))
        ]

    # üìä Gr√°fico: Fraudes ao Longo do Dia
    st.subheader("üìÜ Distribui√ß√£o de Fraudes por Hor√°rio")
    fig, ax = plt.subplots(figsize=(8, 4))
    sns.histplot(fraude_filtrada["Hour"], bins=24, kde=True, color="red", ax=ax)
    ax.set_xlabel("Hora do Dia")
    ax.set_ylabel("N√∫mero de Fraudes")
    st.pyplot(fig)

    # üìç Fraudes por Regi√£o
    st.subheader("üåç Fraudes por Regi√£o")
    fraude_por_regiao = fraude_filtrada["Region"].value_counts(normalize=True) * 100
    fig, ax = plt.subplots(figsize=(8, 4))
    sns.barplot(x=fraude_por_regiao.index, y=fraude_por_regiao.values, palette="Reds_r", ax=ax)
    ax.set_ylabel("Percentagem de Fraudes (%)")
    st.pyplot(fig)

    # üìà Boxplot: Distribui√ß√£o dos Valores Fraudulentos
    st.subheader("üí∞ An√°lise dos Valores das Fraudes")
    fig, ax = plt.subplots(figsize=(8, 4))
    sns.boxplot(x=fraude_filtrada["Amount"], color="red", ax=ax)
    ax.set_xlabel("Valor da Fraude ($)")
    st.pyplot(fig)

    # üìä Heatmap: Fraudes por Hora e Regi√£o
    st.subheader("üî• Mapa de Calor: Fraudes por Hora e Regi√£o")
    heatmap_data = fraud.pivot_table(index="Region", columns="Hour", values="Class", aggfunc="count", fill_value=0)
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.heatmap(heatmap_data, cmap="Reds", linewidths=0.5, ax=ax)
    st.pyplot(fig)

    # üìå Insights Autom√°ticos
    st.subheader("üìå Insights Autom√°ticos")
    if len(fraude_filtrada) > 0:
        max_hora = fraude_filtrada["Hour"].value_counts().idxmax()
        max_regiao = fraude_filtrada["Region"].mode()[0]
        st.write(f"üìå **A maior concentra√ß√£o de fraudes ocorre √†s {max_hora}h.**")
        st.write(f"üìå **A regi√£o mais afetada √© {max_regiao}.**")
        st.write(f"üìå **O valor m√©dio das fraudes √© ${fraude_filtrada['Amount'].mean():.2f}.**")
        st.write(f"üìå **O maior valor de fraude registrado foi ${fraude_filtrada['Amount'].max():.2f}.**")
    else:
        st.write("‚úÖ Nenhuma fraude encontrada para os filtros selecionados.")

    # üì§ Exporta√ß√£o de Dados
    st.subheader("üì• Exportar Dados Filtrados")
    csv_filtros = fraude_filtrada.to_csv(index=False).encode('utf-8')
    st.download_button(label="üì• Baixar CSV", data=csv_filtros, file_name="fraudes_filtradas.csv", mime="text/csv")


# üìà P√°gina de Estat√≠sticas
elif page == "üìà Estat√≠sticas":
    st.markdown('<p class="big-font">üìà Estat√≠sticas Avan√ßadas</p>', unsafe_allow_html=True)

    st.subheader("üìä M√©dias e Medianas")
    col1, col2 = st.columns(2)
    col1.write("### M√©dia:")
    col1.write(df.mean(numeric_only=True))
    col2.write("### Mediana:")
    col2.write(df.median(numeric_only=True))

    st.subheader("üìä Vari√¢ncia e Desvio Padr√£o")
    col1, col2 = st.columns(2)
    col1.write("### Vari√¢ncia:")
    col1.write(df.var(numeric_only=True))
    col2.write("### Desvio Padr√£o:")
    col2.write(df.std(numeric_only=True))

    # üî• Matriz de Correla√ß√£o
    st.subheader("üî• Matriz de Correla√ß√£o")
    fig, ax = plt.subplots(figsize=(10, 8))
    df_numeric = df.select_dtypes(include=["number"])
    sns.heatmap(df_numeric.corr(), cmap="coolwarm", annot=False, ax=ax)
    st.pyplot(fig)

    # Explica√ß√£o sobre as correla√ß√µes
    st.write("""
    üìå **An√°lise das Correla√ß√µes:**
    - **Correla√ß√µes Positivas Fortes:**
    - Rolling_Mean_Amount e Std_Amount: Correla√ß√£o positiva forte
    - Num_Transacoes_1h e algumas vari√°veis V: Correla√ß√µes positivas moderadas

    - **Correla√ß√µes Negativas Importantes:**
    - Delta_Amount e Rolling_Mean_Amount: Correla√ß√£o negativa moderada
    - Time_Diff e algumas vari√°veis V: Correla√ß√µes negativas moderadas
    - Delta_Media_Valor e Amount: Diferen√ßas em rela√ß√£o √† m√©dia tendem a ser inversas ao valor total da transa√ß√£o
    """)

    # üìä Matriz de Covari√¢ncia
    st.subheader("üìä Matriz de Covari√¢ncia")
    st.write(df_numeric.cov())

    # üìå An√°lise de Fraudes por Valor e Regi√£o
    st.subheader("üí∞ Fraudes por Valor e Regi√£o")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.violinplot(data=df, x="Region", y="Amount", hue="Class", split=True, ax=ax)
    ax.set_xlabel("Regi√£o")
    ax.set_ylabel("Valor da Transa√ß√£o")
    st.pyplot(fig)

    # üìå Insights Autom√°ticos
    st.markdown("### üìå Insights Autom√°ticos")
    if df["Class"].sum() > 0:
        regiao_mais_fraudulenta = df[df["Class"] == 1]["Region"].mode()[0]
        valor_medio_fraude = df[df["Class"] == 1]["Amount"].mean()
        st.write(f"üìå **A regi√£o com mais fraudes √© {regiao_mais_fraudulenta}.**")
        st.write(f"üìå **O valor m√©dio de uma transa√ß√£o fraudulenta √© de R$ {valor_medio_fraude:.2f}.**")
    else:
        st.write("Nenhuma fraude detectada nos dados.")

# P√°gina 4: Relat√≥rios e Configura√ß√µes
elif page == "üìÇ Relat√≥rios e Configura√ß√µes":
    st.markdown('<p class="big-font">üìÇ Relat√≥rios e Configura√ß√µes</p>', unsafe_allow_html=True)

    # Definindo sub-p√°ginas
    sub_page = st.sidebar.radio("Subt√≥picos", ["üìë Gerar Relat√≥rio", "‚öô Configura√ß√µes Avan√ßadas", "üîÑ Normaliza√ß√£o e Padroniza√ß√£o"])

    # üìë Gera√ß√£o de Relat√≥rios Personalizados
    if sub_page == "üìë Gerar Relat√≥rio":
        st.subheader("üì• Exporta√ß√£o de Dados")

        # üéØ Filtros Avan√ßados para o Relat√≥rio
        colunas_disponiveis = list(df.columns)
        colunas_selecionadas = st.multiselect("Selecione as colunas para o relat√≥rio", colunas_disponiveis,
                                              default=colunas_disponiveis)

        tipo_transacao = st.radio("Filtrar transa√ß√µes:", ["Todas", "Apenas Fraudes", "Apenas Leg√≠timas"])

        if tipo_transacao == "Apenas Fraudes":
            df_export = df[df["Class"] == 1]
        elif tipo_transacao == "Apenas Leg√≠timas":
            df_export = df[df["Class"] == 0]
        else:
            df_export = df.copy()

        df_export = df_export[colunas_selecionadas]

        # üìä Visualizar os dados antes do download
        st.write("üîç **Pr√©-visualiza√ß√£o dos Dados:**")
        st.dataframe(df_export.head(10))

        # üìä Distribui√ß√£o de Categorias de Montante
        st.subheader("üìä Distribui√ß√£o de Categorias de Montante")
        fig, ax = plt.subplots(figsize=(8, 4))
        df["Amount_Category"].value_counts().plot(kind="bar", color="skyblue", ax=ax)
        ax.set_xlabel("Categoria de Montante")
        ax.set_ylabel("N√∫mero de Transa√ß√µes")
        st.pyplot(fig)

        # üåô Propor√ß√£o de Transa√ß√µes Noturnas
        st.subheader("üåô Propor√ß√£o de Transa√ß√µes Noturnas")
        transacao_noturna = df["Transacao_Noturna"].value_counts(normalize=True) * 100
        st.write(f"**Transa√ß√µes Noturnas:** {transacao_noturna[1]:.2f}%")
        st.write(f"**Transa√ß√µes Diurnas:** {transacao_noturna[0]:.2f}%")

        # üìà M√©dia M√≥vel do Montante
        st.subheader("üìà M√©dia M√≥vel do Montante")
        fig, ax = plt.subplots(figsize=(10, 5))
        df["Rolling_Mean_Amount"].plot(ax=ax, color="blue", label="M√©dia M√≥vel (5 Transa√ß√µes)")
        ax.set_xlabel("√çndice")
        ax.set_ylabel("Montante ($)")
        ax.legend()
        st.pyplot(fig)

        # ‚è±Ô∏è Diferen√ßa de Tempo entre Transa√ß√µes
        st.subheader("‚è±Ô∏è Diferen√ßa de Tempo entre Transa√ß√µes")
        fig, ax = plt.subplots(figsize=(8, 4))
        sns.histplot(df["Time_Diff"].dropna(), bins=30, kde=True, color="purple", ax=ax)
        ax.set_xlabel("Diferen√ßa de Tempo (segundos)")
        ax.set_ylabel("Frequ√™ncia")
        st.pyplot(fig)

        # üî• Mapa de Calor: N√∫mero de Transa√ß√µes por Hora e Regi√£o
        st.subheader("üî• Mapa de Calor: N√∫mero de Transa√ß√µes por Hora e Regi√£o")
        heatmap_data = df.pivot_table(index="Region", columns="Hour", values="Num_Transacoes_1h", aggfunc="mean",
                                      fill_value=0)
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.heatmap(heatmap_data, cmap="Blues", linewidths=0.5, ax=ax)
        st.pyplot(fig)

        # üìÇ Op√ß√µes de Exporta√ß√£o
        formato = st.selectbox("Escolha o formato do relat√≥rio:", ["CSV", "Excel"])
        if formato == "CSV":
            file_data = df_export.to_csv(index=False).encode('utf-8')
            file_name = "relatorio_fraude.csv"
            mime_type = "text/csv"
        else:
            file_data = df_export.to_excel(index=False).encode('utf-8')
            file_name = "relatorio_fraude.xlsx"
            mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"

        st.download_button(label=f"üì• Baixar {formato}", data=file_data, file_name=file_name, mime=mime_type)

    # ‚öô Configura√ß√µes Avan√ßadas
    elif sub_page == "‚öô Configura√ß√µes Avan√ßadas":
        st.subheader("‚öô Ajustes do Sistema")

        # üìå Configura√ß√£o de Alertas de Fraude
        limite_alerta = st.slider("Definir limite de alerta para transa√ß√µes suspeitas ($):", 10, 5000, 1000)
        metodo_analise = st.radio("Escolha o m√©todo de detec√ß√£o de fraudes:", ["Regra Fixa", "Machine Learning"])

        # üåç Configura√ß√£o de Regi√µes
        st.subheader("üåé Personalizar An√°lise por Regi√£o")
        selected_region = st.multiselect("Selecione as regi√µes a monitorar:", df["Region"].unique(),
                                         default=df["Region"].unique())

        # üéØ Aplicar configura√ß√µes (Simula√ß√£o)
        if st.button("Salvar Configura√ß√µes"):
            st.success("‚úÖ Configura√ß√µes salvas com sucesso!")
            st.write(f"- **Limite de Alerta:** ${limite_alerta}")
            st.write(f"- **M√©todo de Detec√ß√£o:** {metodo_analise}")
            st.write(f"- **Regi√µes Monitoradas:** {', '.join(selected_region)}")

    # üîÑ Normaliza√ß√£o e Padroniza√ß√£o
    elif sub_page == "üîÑ Normaliza√ß√£o e Padroniza√ß√£o":
        st.subheader("üîÑ Padroniza√ß√£o e Normaliza√ß√£o de Dados")
        
        st.write("""
        ## Padroniza√ß√£o (Standardization)

        A padroniza√ß√£o (Z-score normalization) √© uma t√©cnica de pr√©-processamento de dados que transforma os valores 
        para que tenham m√©dia 0 e desvio padr√£o 1.
        """)

        # F√≥rmula matem√°tica com LaTeX
        st.latex(r'Z = \frac{X - \mu}{\sigma}')
        
        st.write("""
        onde:
        - X = valor original
        - Œº = m√©dia da distribui√ß√£o 
        - œÉ = desvio padr√£o da distribui√ß√£o
        
        **Caracter√≠sticas:**
        - Resulta em dados com m√©dia 0
        - Resulta em dados com desvio padr√£o 1
        - √ötil quando os dados seguem distribui√ß√£o normal
        - Preserva outliers (valores extremos)
        
        **Vantagens:**
        - Facilita a compara√ß√£o entre diferentes atributos
        - Essencial para algoritmos sens√≠veis √† escala (como SVM, K-means, PCA)
        - Melhora a converg√™ncia em algoritmos de gradient descent
        """)
        
        # Demonstra√ß√£o de padroniza√ß√£o com os dados
        with st.expander("üîç Demonstra√ß√£o de Padroniza√ß√£o"):
            # Selecionar uma coluna para demonstra√ß√£o
            selected_column = st.selectbox("Selecione uma coluna para padroniza√ß√£o:", 
                                          df.select_dtypes(include=['number']).columns)
            
            # Calcular m√©dia e desvio padr√£o
            mean_value = df[selected_column].mean()
            std_value = df[selected_column].std()
            
            # Criar uma amostra de dados padronizados
            original_data = df[selected_column].head(10).values
            standardized_data = (original_data - mean_value) / std_value
            
            # Mostrar uma compara√ß√£o
            comparison_df = pd.DataFrame({
                "Original": original_data,
                "Padronizado": standardized_data
            })
            
            st.write("**Dados Originais vs. Padronizados:**")
            st.write(comparison_df)
            
            # Mostrar estat√≠sticas
            st.write(f"**M√©dia Original:** {mean_value:.4f}")
            st.write(f"**Desvio Padr√£o Original:** {std_value:.4f}")
            st.write(f"**M√©dia dos Dados Padronizados:** {standardized_data.mean():.4f}")
            st.write(f"**Desvio Padr√£o dos Dados Padronizados:** {standardized_data.std():.4f}")
            
            # Plotar compara√ß√£o
            fig, ax = plt.subplots(1, 2, figsize=(10, 4))
            ax[0].hist(original_data, bins=10, color='blue', alpha=0.7)
            ax[0].set_title("Dados Originais")
            ax[1].hist(standardized_data, bins=10, color='green', alpha=0.7)
            ax[1].set_title("Dados Padronizados")
            st.pyplot(fig)
        
        st.write("""
        ## Normaliza√ß√£o (Min-Max Scaling)

        A normaliza√ß√£o transforma os dados para um intervalo espec√≠fico, tipicamente [0,1] ou [-1,1].
        """)
        
        # F√≥rmula matem√°tica com LaTeX
        st.latex(r"X' = \frac{X - X_{min}}{X_{max} - X_{min}}")
        
        st.write("""
        onde:
        - X = valor original
        - Xmin = valor m√≠nimo do atributo
        - Xmax = valor m√°ximo do atributo
        
        **Caracter√≠sticas:**
        - Escala os dados para um intervalo fixo
        - Preserva a distribui√ß√£o original dos dados
        - √ötil quando a distribui√ß√£o n√£o √© gaussiana
        - Mant√©m rela√ß√µes entre valores originais
        
        **Vantagens:**
        - Facilita compara√ß√£o entre vari√°veis de unidades diferentes
        - √ötil para algoritmos que exigem valores limitados
        - Boa para t√©cnicas como redes neurais e algoritmos baseados em dist√¢ncia
        """)
        
        # Demonstra√ß√£o de normaliza√ß√£o com os dados
        with st.expander("üîç Demonstra√ß√£o de Normaliza√ß√£o"):
            # Selecionar uma coluna para demonstra√ß√£o
            selected_column = st.selectbox("Selecione uma coluna para normaliza√ß√£o:", 
                                          df.select_dtypes(include=['number']).columns,
                                          key="normalization_column")
            
            # Calcular min e max
            min_value = df[selected_column].min()
            max_value = df[selected_column].max()
            
            # Criar uma amostra de dados normalizados
            original_data = df[selected_column].head(10).values
            normalized_data = (original_data - min_value) / (max_value - min_value)
            
            # Mostrar uma compara√ß√£o
            comparison_df = pd.DataFrame({
                "Original": original_data,
                "Normalizado": normalized_data
            })
            
            st.write("**Dados Originais vs. Normalizados:**")
            st.write(comparison_df)
            
            # Mostrar estat√≠sticas
            st.write(f"**Valor M√≠nimo Original:** {min_value:.4f}")
            st.write(f"**Valor M√°ximo Original:** {max_value:.4f}")
            st.write(f"**Valor M√≠nimo Normalizado:** {normalized_data.min():.4f}")
            st.write(f"**Valor M√°ximo Normalizado:** {normalized_data.max():.4f}")
            
            # Plotar compara√ß√£o
            fig, ax = plt.subplots(1, 2, figsize=(10, 4))
            ax[0].hist(original_data, bins=10, color='blue', alpha=0.7)
            ax[0].set_title("Dados Originais")
            ax[1].hist(normalized_data, bins=10, color='red', alpha=0.7)
            ax[1].set_title("Dados Normalizados")
            st.pyplot(fig)
        
        st.write("""
        ## Quando Usar Cada T√©cnica
        
        **Use Padroniza√ß√£o quando:**
        - Os dados seguem distribui√ß√£o normal ou pr√≥xima dela
        - O algoritmo pressup√µe normalidade dos dados
        - H√° presen√ßa significativa de outliers que n√£o devem ser ocultados
        - Trabalhando com algoritmos como SVM, regress√£o linear, ou PCA
        
        **Use Normaliza√ß√£o quando:**
        - Precisa de um intervalo espec√≠fico e limitado
        - Trabalhando com redes neurais, especialmente com fun√ß√µes de ativa√ß√£o que esperam entradas em [0,1] ou [-1,1]
        - A distribui√ß√£o dos dados n√£o √© gaussiana
        - A escala absoluta √© importante para o algoritmo
        
        ## Import√¢ncia no Big Data
        
        - Permite comparabilidade entre diferentes fontes de dados
        - Reduz o impacto de diferentes magnitudes entre vari√°veis
        - Essencial para algoritmos de aprendizado de m√°quina que s√£o sens√≠veis √† escala
        - Melhora a qualidade dos resultados de clustering e classifica√ß√£o
        - Facilita a integra√ß√£o de dados heterog√™neos
        """)
        
        # Aplica√ß√£o pr√°tica
        st.subheader("üß™ Aplica√ß√£o Pr√°tica")
        
        st.write("""
        Exemplo pr√°tico de como a padroniza√ß√£o e normaliza√ß√£o podem afetar a detec√ß√£o de fraudes:
        
        Considere as vari√°veis 'Amount' e 'Time' que possuem escalas muito diferentes. Um algoritmo de detec√ß√£o de fraude 
        baseado em dist√¢ncia (como KNN) daria peso desproporcional √† vari√°vel com maior magnitude. Ao normalizar ou 
        padronizar, ambas as vari√°veis t√™m peso equivalente na decis√£o do algoritmo.
        """)
        
        # Compara√ß√£o visual final
        st.subheader("üìä Compara√ß√£o Visual")
        
        # Selecionar duas colunas para visualiza√ß√£o
        col1, col2 = st.columns(2)
        with col1:
            selected_column1 = st.selectbox("Selecione a primeira coluna:", 
                                           df.select_dtypes(include=['number']).columns,
                                           key="vis_column1")
        with col2:
            selected_column2 = st.selectbox("Selecione a segunda coluna:", 
                                           df.select_dtypes(include=['number']).columns,
                                           key="vis_column2")
        
        # Amostrar dados para evitar sobrecarga
        sample_size = min(1000, len(df))
        sample_df = df.sample(sample_size, random_state=42)
        
        # Dados originais
        fig, ax = plt.subplots(figsize=(8, 6))
        ax.scatter(sample_df[selected_column1], sample_df[selected_column2], 
                   c=sample_df['Class'], cmap='coolwarm', alpha=0.6)
        ax.set_xlabel(selected_column1)
        ax.set_ylabel(selected_column2)
        ax.set_title("Dados Originais")
        # Adicionar legenda manual
        import matplotlib.patches as mpatches
        red_patch = mpatches.Patch(color='red', label='Fraude')
        blue_patch = mpatches.Patch(color='blue', label='Leg√≠tima')
        ax.legend(handles=[red_patch, blue_patch])
        
        st.pyplot(fig)
        
        # Dados padronizados
        from sklearn.preprocessing import StandardScaler, MinMaxScaler
        
        # Preparar os dados
        X = sample_df[[selected_column1, selected_column2]].values
        y = sample_df['Class'].values
        
        # Padronizar
        scaler = StandardScaler()
        X_std = scaler.fit_transform(X)
        
        # Normalizar
        min_max_scaler = MinMaxScaler()
        X_norm = min_max_scaler.fit_transform(X)
        
        # Plotar dados padronizados
        fig, ax = plt.subplots(1, 2, figsize=(12, 5))
        
        # Padronizado
        ax[0].scatter(X_std[:, 0], X_std[:, 1], c=y, cmap='coolwarm', alpha=0.6)
        ax[0].set_xlabel(f"{selected_column1} (padronizado)")
        ax[0].set_ylabel(f"{selected_column2} (padronizado)")
        ax[0].set_title("Dados Padronizados")
        
        # Normalizado
        ax[1].scatter(X_norm[:, 0], X_norm[:, 1], c=y, cmap='coolwarm', alpha=0.6)
        ax[1].set_xlabel(f"{selected_column1} (normalizado)")
        ax[1].set_ylabel(f"{selected_column2} (normalizado)")
        ax[1].set_title("Dados Normalizados")
        
        plt.tight_layout()
        st.pyplot(fig)
        

# Nova p√°gina: Dados
elif page == "üß≠ Dados":
    st.markdown('<p class="big-font">üß≠ Dados</p>', unsafe_allow_html=True)

    st.subheader("üìä Dashboard de Vari√°veis")

    # Exibir as vari√°veis e seus valores
    variaveis_valores = {
        "Total de Transa√ß√µes": len(df),
        "Transa√ß√µes Fraudulentas": df["Class"].sum(),
        "Taxa de Fraude (%)": (df["Class"].sum() / len(df)) * 100,
        "Valor M√©dio das Transa√ß√µes ($)": df["Amount"].mean(),
        "Valor M√°ximo das Transa√ß√µes ($)": df["Amount"].max(),
        "Valor M√≠nimo das Transa√ß√µes ($)": df["Amount"].min(),
        "Desvio Padr√£o do Valor das Transa√ß√µes ($)": df["Amount"].std()
    }

    for variavel, valor in variaveis_valores.items():
        st.metric(label=variavel, value=f"{valor:,.2f}" if isinstance(valor, float) else f"{valor:,}")

    # Adicionar scope das vari√°veis
    st.subheader("üìÑ Scope das Vari√°veis")

    variaveis_escopo = {
        "Time": "Tempo decorrido desde a primeira transa√ß√£o no dataset.",
        "Vx": "Vari√°veis anonimizadas resultantes de PCA (28 componentes principais).",
        "Amount": "Montante da transa√ß√£o.",
        "Class": "Classe da transa√ß√£o (0: Leg√≠tima, 1: Fraudulenta).",
        "Hour": "Hora do dia em que a transa√ß√£o ocorreu.",
        "Rolling_Mean_Amount": "M√©dia m√≥vel do valor da transa√ß√£o (janela de 5 transa√ß√µes).",
        "Std_Amount": "Desvio padr√£o do valor da transa√ß√£o (janela de 5 transa√ß√µes).",
        "Delta_Amount": "Diferen√ßa entre o valor atual e o valor anterior da transa√ß√£o.",
        "Amount_Category": "Categoria do valor da transa√ß√£o (ex.: Muito Baixo, Baixo, M√©dio, etc.).",
        "Time_Diff": "Diferen√ßa de tempo entre transa√ß√µes consecutivas.",
        "Transacao_Noturna": "Indica se a transa√ß√£o ocorreu durante a noite (1: Sim, 0: N√£o).",
        "Num_Transacoes_1h": "N√∫mero de transa√ß√µes realizadas na mesma hora.",
        "Freq_Valor_Transacao": "Frequ√™ncia de transa√ß√µes com o mesmo valor.",
        "Delta_Media_Valor": "Diferen√ßa entre o valor da transa√ß√£o e a m√©dia m√≥vel.",
        "Region": "Regi√£o geogr√°fica associada √† transa√ß√£o."
    }

    for variavel, descricao in variaveis_escopo.items():
        st.write(f"**{variavel}:** {descricao}")

    # Adicionar gr√°ficos de valores m√≠nimo e m√°ximo
    st.subheader("üìä Gr√°ficos de Valores M√≠nimo e M√°ximo")

    # Agregar dados de V1-V28 em Vx
    df["Vx"] = df[[f"V{i}" for i in range(1, 29)]].sum(axis=1)
    min_vals = df[["Vx", "Hour", "Time_Diff"]].min()
    max_vals = df[["Vx", "Hour", "Time_Diff"]].max()

    fig, ax = plt.subplots(figsize=(12, 6))
    ax.bar(min_vals.index, min_vals.values, color="blue", label="Min")
    ax.bar(max_vals.index, max_vals.values, color="red", label="Max", alpha=0.7)
    ax.set_title("Valores M√≠nimo e M√°ximo de Vx, Hour e Time_Diff")
    ax.set_ylabel("Valores")
    ax.legend()
    plt.xticks(rotation=90)
    st.pyplot(fig)

    # Adicionar gr√°ficos de valores m√≠nimo e m√°ximo
    st.subheader("üìä Gr√°ficos de Valores M√≠nimo e M√°ximo")

    # Remover colunas indesejadas
    columns_to_exclude = [f"V{i}" for i in range(1, 29)] + ["Vx", "Hour", "Time_Diff", "Class", "Transacao_Noturna"]
    numeric_columns = df.select_dtypes(include=['number']).columns
    numeric_columns = [col for col in numeric_columns if col not in columns_to_exclude]

    # Calcular valores m√≠nimos e m√°ximos apenas para colunas num√©ricas filtradas
    min_vals = df[numeric_columns].min()
    max_vals = df[numeric_columns].max()

    # Garantir que os √≠ndices sejam strings
    min_vals.index = min_vals.index.astype(str)
    max_vals.index = max_vals.index.astype(str)

    # Garantir que os valores sejam num√©ricos
    min_vals = pd.to_numeric(min_vals, errors='coerce').fillna(0)
    max_vals = pd.to_numeric(max_vals, errors='coerce').fillna(0)

    # Criar o gr√°fico
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.bar(min_vals.index, min_vals.values, color="blue", label="Min")
    ax.bar(max_vals.index, max_vals.values, color="red", label="Max", alpha=0.7)
    ax.set_title("Valores M√≠nimo e M√°ximo das Vari√°veis Especificadas")
    ax.set_ylabel("Valores")
    ax.legend()
    plt.xticks(rotation=90)
    st.pyplot(fig)

    # Adicionar legenda explicativa
    st.markdown("""
    **Legenda:**
    - **Min**: O valor m√≠nimo registrado para a vari√°vel.
    - **Max**: O valor m√°ximo registrado para a vari√°vel.
    Estes valores ajudam a entender a amplitude e a varia√ß√£o dos dados para cada vari√°vel.
    """)

# Nova p√°gina: Machine Learning
elif page == "ü§ñ Machine Learning":
    # Adicionar tabs para diferentes modelos de ML
    model_tabs = st.tabs(["Introdu√ß√£o", "Classifica√ß√£o", "Ridge e Lasso Regression"])
    
    with model_tabs[0]:
        # Mover o conte√∫do existente sobre ML para esta tab
        st.markdown("## Introdu√ß√£o ao Machine Learning")
        
        # Conceitos b√°sicos
        st.subheader("üîç Conceitos B√°sicos")
        st.write("""
        **Machine Learning (ML)** √© um subcampo da Intelig√™ncia Artificial que permite aos computadores aprender 
        sem programa√ß√£o expl√≠cita. Ao contr√°rio da programa√ß√£o tradicional onde escrevemos regras espec√≠ficas, 
        no ML os algoritmos aprendem padr√µes diretamente a partir dos dados.
        
        A principal diferen√ßa √© que em ML:
        - Os dados ensinam o computador
        - O sistema melhora com a experi√™ncia
        - Identifica padr√µes estatisticamente significativos
        """)
        
        # Compara√ß√£o visual entre programa√ß√£o tradicional e ML
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### üíª Programa√ß√£o Tradicional")
            st.markdown("""
            ```
            Dados + Regras ‚Üí Resultados
            ```
            """)
            st.write("As regras s√£o definidas pelo programador")
            
        with col2:
            st.markdown("### ü§ñ Machine Learning")
            st.markdown("""
            ```
            Dados + Resultados ‚Üí Regras
            ```
            """)
            st.write("As regras s√£o descobertas pelo algoritmo")
        
        # Tipos de aprendizado
        st.subheader("üìö Tipos de Aprendizado")
        
        tab1, tab2, tab3 = st.tabs(["Supervisionado", "N√£o Supervisionado", "Por Refor√ßo"])
        
        with tab1:
            st.markdown("### Aprendizado Supervisionado")
            st.write("""
            No aprendizado supervisionado, o algoritmo √© treinado em um conjunto de dados rotulado, 
            onde para cada exemplo temos uma entrada e a sa√≠da desejada.
            
            **Exemplos de aplica√ß√µes:**
            - Classifica√ß√£o de e-mails em spam ou n√£o-spam
            - Previs√£o de pre√ßos de im√≥veis
            - Diagn√≥stico m√©dico
            
            **Algoritmos populares:**
            - Regress√£o Linear/Log√≠stica
            - √Årvores de Decis√£o
            - Random Forests
            - Support Vector Machines (SVM)
            - Redes Neurais
            """)
            
            # Demonstra√ß√£o visual simples
            st.markdown("#### Exemplo: Classifica√ß√£o de Fraudes")
            
            fig, ax = plt.subplots(figsize=(6, 4))
            
            # Amostra pequena para demonstra√ß√£o
            sample = df.sample(100, random_state=42)
            ax.scatter(sample["Amount"], sample["V1"], c=sample["Class"], cmap="coolwarm", s=50)
            ax.set_xlabel("Valor da Transa√ß√£o")
            ax.set_ylabel("Componente V1")
            ax.set_title("Exemplo de Classifica√ß√£o: Transa√ß√µes Leg√≠timas vs Fraudulentas")
            
            # Adicionar legenda manual
            import matplotlib.patches as mpatches
            red_patch = mpatches.Patch(color='red', label='Fraude')
            blue_patch = mpatches.Patch(color='blue', label='Leg√≠tima')
            ax.legend(handles=[red_patch, blue_patch])
            
            st.pyplot(fig)
        
        with tab2:
            st.markdown("### Aprendizado N√£o Supervisionado")
            st.write("""
            No aprendizado n√£o supervisionado, o algoritmo trabalha com dados n√£o rotulados, 
            buscando encontrar estruturas ou padr√µes intr√≠nsecos nos dados.
            
            **Exemplos de aplica√ß√µes:**
            - Segmenta√ß√£o de clientes
            - Agrupamento de not√≠cias semelhantes
            - Detec√ß√£o de anomalias
            - Redu√ß√£o de dimensionalidade
            
            **Algoritmos populares:**
            - K-means
            - DBSCAN
            - Hierarchical Clustering
            - PCA (Principal Component Analysis)
            - t-SNE
            """)
            
            # Demonstra√ß√£o visual de clustering
            st.markdown("#### Exemplo: Clustering de Transa√ß√µes")
            
            from sklearn.cluster import KMeans
            
            # Amostra para demonstra√ß√£o
            sample = df.sample(200, random_state=42)
            X = sample[["Amount", "V1"]].values
            
            # Aplicar K-means
            kmeans = KMeans(n_clusters=3, random_state=42)
            sample_clusters = kmeans.fit_predict(X)
            
            # Visualizar
            fig, ax = plt.subplots(figsize=(6, 4))
            scatter = ax.scatter(X[:, 0], X[:, 1], c=sample_clusters, cmap="viridis", s=50)
            ax.set_xlabel("Valor da Transa√ß√£o")
            ax.set_ylabel("Componente V1")
            ax.set_title("Clustering de Transa√ß√µes (K-means, k=3)")
            
            # Adicionar centr√≥ides
            ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], 
                      marker='X', s=200, color='red', label='Centr√≥ides')
            ax.legend()
            
            st.pyplot(fig)
        
        with tab3:
            st.markdown("### Aprendizagem por Refor√ßo")
            st.write("""
            No aprendizagem por refor√ßo, o algoritmo aprende a tomar decis√µes interagindo com um ambiente,
            recebendo recompensas ou penaliza√ß√µes pelas a√ß√µes tomadas.
            """)
            
            st.image("https://cdn-images-1.medium.com/max/800/1*Z2yMvuRTXcMHRdHzKMRM5w.png", 
                    caption="Ciclo de Aprendizado por Refor√ßo", width=400)
    
    # Processo de Machine Learning
    st.subheader("‚öôÔ∏è Processo de Machine Learning")
    
    process_steps = {
        "1. Prepara√ß√£o de Dados": "Coleta, limpeza, normaliza√ß√£o e divis√£o em conjuntos de treinamento/teste",
        "2. Sele√ß√£o de Modelo": "Escolha do algoritmo mais adequado para o problema",
        "3. Treinamento": "Ajuste dos par√¢metros do modelo usando dados de treinamento",
        "4. Valida√ß√£o": "Avalia√ß√£o do desempenho em dados n√£o vistos anteriormente",
        "5. Ajuste de Hiperpar√¢metros": "Otimiza√ß√£o do modelo para melhorar o desempenho",
        "6. Implanta√ß√£o": "Coloca√ß√£o do modelo em produ√ß√£o",
        "7. Monitoramento": "Acompanhamento cont√≠nuo do desempenho"
    }
    
    col1, col2 = st.columns(2)
    
    for i, (step, desc) in enumerate(process_steps.items()):
        if i < 4:
            col1.markdown(f"**{step}:** {desc}")
        else:
            col2.markdown(f"**{step}:** {desc}")
    
    # Aplica√ß√µes em detec√ß√£o de fraude
    st.subheader("üí≥ Machine Learning na Detec√ß√£o de Fraudes")
    
    st.write("""
    A detec√ß√£o de fraudes √© uma das aplica√ß√µes mais importantes de machine learning no setor financeiro.
    Algoritmos ML podem identificar padr√µes suspeitos e anomalias que seriam dif√≠ceis de detectar manualmente.
    
    **Benef√≠cios:**
    
    - **Processamento em tempo real**: an√°lise de transa√ß√µes √† medida que ocorrem
    - **Adaptabilidade**: aprendizado cont√≠nuo com novos padr√µes de fraude
    - **Redu√ß√£o de falsos positivos**: melhoria na precis√£o da detec√ß√£o
    - **Escalabilidade**: capacidade de processar milh√µes de transa√ß√µes
    
    **Desafios:**
    
    - **Dados desbalanceados**: geralmente h√° muito mais transa√ß√µes leg√≠timas que fraudulentas
    - **Adapta√ß√£o a novas fraudes**: fraudadores evoluem constantemente suas t√©cnicas
    - **Lat√™ncia**: necessidade de respostas em milissegundos
    - **Dados sens√≠veis**: quest√µes de privacidade e seguran√ßa
    """)
    
    # M√©tricas de avalia√ß√£o
    st.subheader("üìè M√©tricas de Avalia√ß√£o em Detec√ß√£o de Fraudes")
    
    metrics = {
        "Acur√°cia": "Porcentagem total de previs√µes corretas",
        "Precis√£o": "Entre os casos classificados como fraude, quantos realmente s√£o fraude",
        "Recall (Sensibilidade)": "Entre as fraudes reais, quantas foram detectadas corretamente",
        "F1-Score": "M√©dia harm√¥nica entre precis√£o e recall",
        "AUC-ROC": "Capacidade de distinguir entre classes (0.5 = aleat√≥rio, 1.0 = perfeito)",
        "Custo de classifica√ß√£o errada": "Perda financeira devido a falsos positivos e falsos negativos"
    }
    
    for metric, desc in metrics.items():
        st.markdown(f"**{metric}**: {desc}")
    
    # Demonstra√ß√£o pr√°tica
    st.subheader("üß™ Demonstra√ß√£o Pr√°tica")
    
    with st.expander("Clique para ver uma demonstra√ß√£o simplificada de detec√ß√£o de fraudes"):
        st.write("""
        Abaixo est√° um exemplo simplificado de como um modelo de classifica√ß√£o pode ser usado para detectar fraudes.
        
        Este exemplo usa apenas duas vari√°veis para facilitar a visualiza√ß√£o, mas modelos reais usariam m√∫ltiplas vari√°veis.
        """)
        
        from sklearn.model_selection import train_test_split
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
        
        # Preparar dados (amostra pequena para demonstra√ß√£o r√°pida)
        sample = df.sample(1000, random_state=42)
        X = sample[["Amount", "V1", "V3", "V4"]].values
        y = sample["Class"].values
        
        # Dividir em treino e teste
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
        
        # Vers√£o mais robusta para o treinamento com SMOTE
        with st.spinner('Treinando o modelo...'):
            model = RandomForestClassifier(n_estimators=10, random_state=42)
            
            # Verificar se h√° amostras suficientes para aplicar SMOTE
            try:
                # Verificar o n√∫mero m√≠nimo de amostras nas classes
                class_counts = np.bincount(y_train)
                min_class_count = class_counts.min()
                
                # Decidir qual m√©todo usar com base no n√∫mero de amostras
                if min_class_count >= 6:  # Para k=5 o SMOTE precisa de pelo menos 6 amostras por classe
                    # SMOTE regular
                    smote = SMOTE(random_state=42)
                    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
                elif min_class_count >= 2:  # Se tiver ao menos 2 amostras, usar k=1
                    st.warning("Poucas amostras na classe minorit√°ria. Usando SMOTE com k=1.")
                    smote = SMOTE(k_neighbors=1, random_state=42)
                    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
                else:
                    # Se mesmo assim n√£o for poss√≠vel, usar os dados originais
                    st.warning("Dados muito desbalanceados. Usando dados originais sem SMOTE.")
                    X_train_resampled, y_train_resampled = X_train, y_train
            except Exception as e:
                # Capturar qualquer erro do SMOTE
                st.error(f"Erro ao aplicar SMOTE: {str(e)}. Usando dados originais.")
                X_train_resampled, y_train_resampled = X_train, y_train
        
        # Treinar o modelo com os dados processados
        model.fit(X_train_resampled, y_train_resampled)
        
        # Fazer previs√µes
        y_pred = model.predict(X_test)
        
        # Avaliar modelo
        st.write("**Acur√°cia do modelo:**", accuracy_score(y_test, y_pred))
        
        # Matriz de confus√£o
        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])  # Especificamos explicitamente as classes 0 e 1
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['Leg√≠tima', 'Fraude'], yticklabels=['Leg√≠tima', 'Fraude'])
        ax.set_xlabel('Previsto')
        ax.set_ylabel('Real')
        ax.set_title('Matriz de Confus√£o')
        st.pyplot(fig)
        
        # Relat√≥rio de classifica√ß√£o
        st.write("**Relat√≥rio de classifica√ß√£o:**")
        st.text(classification_report(y_test, y_pred, zero_division=0))
        
        # Import√¢ncia das features
        importances = model.feature_importances_
        feature_names = ["Amount", "V1", "V3", "V4"]
        
        fig, ax = plt.subplots(figsize=(6, 4))
        ax.bar(feature_names, importances)
        ax.set_ylabel('Import√¢ncia')
        ax.set_title('Import√¢ncia das Features')
        st.pyplot(fig)
        
        st.write("""
        **Observa√ß√£o:** Este √© apenas um exemplo simplificado para fins educativos. 
        Em cen√°rios reais, seriam necess√°rios:
        - Pr√©-processamento mais extenso dos dados
        - Utiliza√ß√£o de mais features
        - Ajuste de hiperpar√¢metros
        - T√©cnicas para lidar com dados desbalanceados
        - Valida√ß√£o cruzada
        """)
    
    with model_tabs[1]:
        # Mover a demonstra√ß√£o de classifica√ß√£o para esta tab
        st.markdown("## Classifica√ß√£o para Detec√ß√£o de Fraudes")
        
        # Carregar dados
        df = pd.read_csv("creditcard.csv")
        df = df.dropna()
        
        # Criar vari√°vel alvo (Class) desbalanceada
        df["Class"] = df["Class"].astype("category")
        
        # Amostra dos dados
        st.subheader("Amostra dos Dados")
        st.write(df.sample(10))
        
        # Contagem das classes
        st.subheader("Distribui√ß√£o das Classes")
        class_counts = df["Class"].value_counts()
        st.bar_chart(class_counts)
        
        # Sele√ß√£o de vari√°veis
        st.subheader("Sele√ß√£o de Vari√°veis")
        
        all_columns = df.columns.tolist()
        target = "Class"
        features = st.multiselect(
            "Selecione as vari√°veis independentes (features):",
            options=all_columns,
            default=all_columns[:-1]  # Selecionar todas menos a √∫ltima (que √© a vari√°vel alvo)
        )
        
        # Garantir que a vari√°vel alvo n√£o esteja entre as features selecionadas
        if target in features:
            features.remove(target)
        
        st.write("Features selecionadas:", features)
        
        # Dividir dados
        X = df[features]
        y = df[target]
        
        # Dividir em treino e teste
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
        
        # Treinamento do modelo
        st.subheader("Treinamento do Modelo")
        
        # Selecionar modelo
        model_type = st.selectbox(
            "Escolha o tipo de modelo:",
            ["Random Forest", "Regress√£o Log√≠stica", "√Årvore de Decis√£o"]
        )

        if model_type == "Random Forest":
            from sklearn import tree

            st.subheader("üå≥ Visualiza√ß√£o de uma √Årvore Individual do Random Forest")
            tree_idx = st.slider("Escolha o √≠ndice da √°rvore para visualizar", 0, len(model.estimators_) - 1, 0)
            fig, ax = plt.subplots(figsize=(16, 6))
            tree.plot_tree(
                model.estimators_[tree_idx],
                feature_names=features,
                class_names=["Leg√≠tima", "Fraude"],
                filled=True,
                rounded=True,
                max_depth=3,  # Limite para facilitar a visualiza√ß√£o
                fontsize=10,
                ax=ax
            )
            st.pyplot(fig)
            st.write(f"**√Årvore exibida:** Estimador {tree_idx} do Random Forest (apenas os 3 primeiros n√≠veis).")
        elif model_type == "Regress√£o Log√≠stica":
            from sklearn.linear_model import LogisticRegression
            model = LogisticRegression(class_weight='balanced', solver='liblinear', max_iter=2000, random_state=42)
        else:
            if model_type == "√Årvore de Decis√£o":
                from sklearn import tree

                # Visualiza√ß√£o da √°rvore
                st.subheader("üå≥ Visualiza√ß√£o da √Årvore de Decis√£o")
                fig, ax = plt.subplots(figsize=(16, 6))
                tree.plot_tree(
                    model,
                    feature_names=features,
                    class_names=["Leg√≠tima", "Fraude"],
                    filled=True,
                    rounded=True,
                    max_depth=3,  # Limite para visualiza√ß√£o
                    fontsize=10,
                    ax=ax
                )
                st.pyplot(fig)
                st.write(
                    "**A √°rvore acima mostra as principais regras de decis√£o aprendidas pelo modelo (apenas os 3 primeiros n√≠veis para facilitar a visualiza√ß√£o).**")

                # An√°lise do √≠ndice Gini
                st.subheader("üìä An√°lise do √çndice Gini dos N√≥s")
                gini_values = model.tree_.impurity
                node_samples = model.tree_.n_node_samples
                gini_df = pd.DataFrame({
                    "N√≥": range(len(gini_values)),
                    "√çndice Gini": gini_values,
                    "Amostras no N√≥": node_samples
                })
                st.write(gini_df.head(10))  # Mostra os 10 primeiros n√≥s

                fig, ax = plt.subplots(figsize=(8, 4))
                ax.plot(gini_df["N√≥"], gini_df["√çndice Gini"], marker="o")
                ax.set_xlabel("N√≥")
                ax.set_ylabel("√çndice Gini")
                ax.set_title("√çndice Gini ao longo dos n√≥s da √°rvore")
                st.pyplot(fig)

                st.write("""
                **O √≠ndice Gini mede a impureza dos n√≥s:**
                - Valor 0: n√≥ puro (todas as amostras da mesma classe)
                - Valor pr√≥ximo de 0.5: mistura equilibrada das classes
                """)
        
        # Treinar modelo
        with st.spinner(f'Treinando o modelo ({model_type})...'):
            # Aplicar SMOTE para balancear as classes
            smote = SMOTE(random_state=42)
            X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
            
            model.fit(X_train_resampled, y_train_resampled)

            # Defina o n√∫mero de componentes do PCA
            n_components = st.slider("N¬∫ de componentes do PCA", 2, min(len(features), 20), 5)

            # Treinamento SEM PCA
            start = time.time()
            model_no_pca = RandomForestClassifier(n_estimators=50, random_state=42)
            model_no_pca.fit(X_train, y_train)
            fit_time_no_pca = time.time() - start
            acc_no_pca = model_no_pca.score(X_test, y_test)

            # Treinamento COM PCA
            pca = PCA(n_components=n_components, random_state=42)
            X_train_pca = pca.fit_transform(X_train)
            X_test_pca = pca.transform(X_test)

            start = time.time()
            model_pca = RandomForestClassifier(n_estimators=50, random_state=42)
            model_pca.fit(X_train_pca, y_train)
            fit_time_pca = time.time() - start
            acc_pca = model_pca.score(X_test_pca, y_test)

            # Exibir resultados
            st.subheader("Compara√ß√£o: Com vs. Sem PCA")
            results = pd.DataFrame({
                "Acur√°cia": [acc_no_pca, acc_pca],
                "Tempo de ajuste (s)": [fit_time_no_pca, fit_time_pca]
            }, index=["Sem PCA", "Com PCA"])
            st.write(results)
        
        # Avalia√ß√£o do modelo
        st.subheader("Avalia√ß√£o do Modelo")
        
        # Fazer previs√µes
        y_pred = model.predict(X_test)
        
        # Acur√°cia
        accuracy = accuracy_score(y_test, y_pred)
        st.write(f"Acur√°cia: {accuracy:.2f}")
        
        # Matriz de confus√£o
        st.subheader("Matriz de Confus√£o")
        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])  # Especificamos explicitamente as classes 0 e 1
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['Leg√≠tima', 'Fraude'], yticklabels=['Leg√≠tima', 'Fraude'])
        ax.set_xlabel('Previsto')
        ax.set_ylabel('Real')
        ax.set_title('Matriz de Confus√£o')
        st.pyplot(fig)
        
        # Relat√≥rio de classifica√ß√£o
        st.write("**Relat√≥rio de classifica√ß√£o:**")
        st.text(classification_report(y_test, y_pred, zero_division=0))
        
        # Import√¢ncia das features (apenas para Random Forest)
        if model_type == "Random Forest":
            st.subheader("Import√¢ncia das Features")
            
            importances = model.feature_importances_
            feature_names = features
            
            # Criar dataframe de import√¢ncias
            importance_df = pd.DataFrame({
                'Feature': feature_names,
                'Import√¢ncia': importances
            }).sort_values(by="Import√¢ncia", ascending=False)
            
            st.write(importance_df)
            
            # Gr√°fico de barras
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.barplot(data=importance_df, x="Import√¢ncia", y="Feature", ax=ax, hue="Import√¢ncia", palette="viridis", legend=False)
            ax.set_title("Import√¢ncia das Features - Random Forest")
            ax.set_xlabel("Features")
            ax.set_ylabel("Import√¢ncia")
            st.pyplot(fig)

        # Add to model_tabs[1] after the existing classification models
        st.subheader("üöÄ Boosting Methods")
        
        st.write("""
        ### Ensemble Methods: Boosting
        
        Boosting algorithms build multiple models sequentially, with each model correcting 
        the errors of its predecessors. These are particularly effective for fraud detection.
        
        - **AdaBoost**: Adaptive Boosting focuses on misclassified instances by increasing their weights
        - **XGBoost**: eXtreme Gradient Boosting uses gradient descent to minimize errors
        """)
        
        # Create columns for the two models
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("#### AdaBoost")
            
            run_ada = st.checkbox("Train AdaBoost Model", value=False)
            if run_ada:
                from sklearn.ensemble import AdaBoostClassifier
                
                # Set parameters
                n_estimators = st.slider("Number of Estimators (AdaBoost)", 50, 300, 100)
                learning_rate = st.slider("Learning Rate (AdaBoost)", 0.01, 2.0, 1.0, 0.01)
                
                with st.spinner("Training AdaBoost model..."):
                    # Start timing
                    start = time.time()
                    
                    # Create and train model
                    ada_model = AdaBoostClassifier(
                        n_estimators=n_estimators,
                        learning_rate=learning_rate,
                        random_state=42
                    )
                    ada_model.fit(X_train_resampled, y_train_resampled)
                    
                    # End timing
                    duration = time.time() - start
                    st.write(f"‚è±Ô∏è Training time: {duration:.2f} seconds")
                    
                    # Make predictions
                    y_pred_ada = ada_model.predict(X_test)
                    
                    # Calculate metrics
                    ada_accuracy = accuracy_score(y_test, y_pred_ada)
                    ada_precision = precision_score(y_test, y_pred_ada, zero_division=0)
                    ada_recall = recall_score(y_test, y_pred_ada, zero_division=0)
                    ada_f1 = f1_score(y_test, y_pred_ada, zero_division=0)
                    
                    # Display metrics
                    st.metric("Accuracy", f"{ada_accuracy:.4f}")
                    st.metric("Precision", f"{ada_precision:.4f}")
                    st.metric("Recall", f"{ada_recall:.4f}")
                    st.metric("F1 Score", f"{ada_f1:.4f}")
                    
                    # Display confusion matrix
                    cm_ada = confusion_matrix(y_test, y_pred_ada)
                    fig, ax = plt.subplots(figsize=(5, 4))
                    sns.heatmap(cm_ada, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['Leg√≠tima', 'Fraude'], yticklabels=['Leg√≠tima', 'Fraude'])
                    ax.set_xlabel('Previsto')
                    ax.set_ylabel('Real')
                    ax.set_title('Matriz de Confus√£o')
                    st.pyplot(fig)
        
        with col2:
            st.write("#### XGBoost")
            
            run_xgb = st.checkbox("Train XGBoost Model", value=False)
            if run_xgb:
                import xgboost as xgb
                
                # Set parameters
                n_estimators_xgb = st.slider("Number of Estimators (XGBoost)", 50, 300, 100)
                max_depth = st.slider("Max Depth (XGBoost)", 3, 10, 6)
                learning_rate_xgb = st.slider("Learning Rate (XGBoost)", 0.01, 0.3, 0.1, 0.01)
                
                with st.spinner("Training XGBoost model..."):
                    # Start timing
                    start = time.time()
                    
                    # Create and train model
                    xgb_model = xgb.XGBClassifier(
                        n_estimators=n_estimators_xgb,
                        max_depth=max_depth,
                        learning_rate=learning_rate_xgb,
                        random_state=42
                    )
                    xgb_model.fit(X_train_resampled, y_train_resampled)
                    
                    # End timing
                    duration = time.time() - start
                    st.write(f"‚è±Ô∏è Training time: {duration:.2f} seconds")
                    
                    # Make predictions
                    y_pred_xgb = xgb_model.predict(X_test)
                    
                    # Calculate metrics
                    xgb_accuracy = accuracy_score(y_test, y_pred_xgb)
                    xgb_precision = precision_score(y_test, y_pred_xgb, zero_division=0)
                    xgb_recall = recall_score(y_test, y_pred_xgb, zero_division=0)
                    xgb_f1 = f1_score(y_test, y_pred_xgb, zero_division=0)
                    
                    # Display metrics
                    st.metric("Accuracy", f"{xgb_accuracy:.4f}")
                    st.metric("Precision", f"{xgb_precision:.4f}")
                    st.metric("Recall", f"{xgb_recall:.4f}")
                    st.metric("F1 Score", f"{xgb_f1:.4f}")
                    
                    # Display confusion matrix
                    cm_xgb = confusion_matrix(y_test, y_pred_xgb)
                    fig, ax = plt.subplots(figsize=(5, 4))
                    sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['Leg√≠tima', 'Fraude'], yticklabels=['Leg√≠tima', 'Fraude'])
                    ax.set_xlabel('Previsto')
                    ax.set_ylabel('Real')
                    ax.set_title('Matriz de Confus√£o')
                    st.pyplot(fig)
                    
                    # Feature importance for XGBoost
                    fig, ax = plt.subplots(figsize=(8, 6))
                    xgb.plot_importance(xgb_model, ax=ax, max_num_features=10)
                    plt.title("XGBoost Feature Importance")
                    st.pyplot(fig)
        
        # Compare boosting models if both have been trained
        if run_ada and run_xgb:
            st.subheader("Comparison of Boosting Methods")
            
            # Create comparison dataframe
            boost_comparison = pd.DataFrame({
                'Model': ['AdaBoost', 'XGBoost'],
                'Accuracy': [ada_accuracy, xgb_accuracy],
                'Precision': [ada_precision, xgb_precision],
                'Recall': [ada_recall, xgb_recall],
                'F1 Score': [ada_f1, xgb_f1]
            })
            
            st.write(boost_comparison)
            
            # Plot comparison
            fig, ax = plt.subplots(figsize=(10, 6))
            
            x = np.arange(2)
            width = 0.2
            metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']
            colors = ['blue', 'green', 'red', 'purple']
            
            for i, metric in enumerate(metrics):
                values = boost_comparison[metric].values
                ax.bar(x + i*width - 0.3, values, width, label=metric, color=colors[i])
            
            ax.set_xticks(x)
            ax.set_xticklabels(boost_comparison['Model'])
            ax.set_ylabel('Score')
            ax.set_title('Boosting Methods Comparison')
            ax.legend()
            
            st.pyplot(fig)
        
        # Add to model_tabs[1] after boosting methods
        st.subheader("üîÑ Support Vector Machines")
        
        st.write("""
        ### SVM with Multiple Kernels
        
        Support Vector Machines (SVMs) are powerful classifiers that work by finding the hyperplane 
        that best separates classes in the feature space. Different kernels allow SVMs to handle 
        both linear and non-linear classification tasks.
        """)
        
        run_svm = st.checkbox("Train SVM Models with Different Kernels", value=False)
        
        if run_svm:
            from sklearn.svm import SVC
            
            # Kernels to test
            kernels = ["linear", "poly", "rbf", "sigmoid"]
            
            # Create dictionary to store results
            svm_results = {}
            training_times = {}
            
            with st.spinner("Training SVM models with different kernels - this may take a while..."):
                for kernel in kernels:
                    # Start timing
                    start = time.time()
                    
                    # Create and train model
                    svm_model = SVC(
                        kernel=kernel,
                        probability=True,
                        random_state=42,
                        class_weight='balanced'
                    )
                    
                    # Fit model
                    svm_model.fit(X_train_resampled, y_train_resampled)
                    
                    # End timing
                    duration = time.time() - start
                    training_times[kernel] = duration
                    
                    # Make predictions
                    y_pred_svm = svm_model.predict(X_test)
                    
                    # Calculate metrics
                    svm_accuracy = accuracy_score(y_test, y_pred_svm)
                    svm_precision = precision_score(y_test, y_pred_svm, zero_division=0)
                    svm_recall = recall_score(y_test, y_pred_svm, zero_division=0)
                    svm_f1 = f1_score(y_test, y_pred_svm, zero_division=0)
                    
                    # Store results
                    svm_results[kernel] = {
                        'Accuracy': svm_accuracy,
                        'Precision': svm_precision,
                        'Recall': svm_recall,
                        'F1 Score': svm_f1,
                        'Training Time': duration
                    }
            
            # Display results as table
            st.write("### SVM Performance by Kernel Type")
            svm_df = pd.DataFrame.from_dict(svm_results, orient='index')
            st.write(svm_df)
            
            # Find best kernel
            best_kernel = svm_df['F1 Score'].idxmax()
            st.write(f"Best kernel based on F1 Score: **{best_kernel}**")
            
            # Plot performance metrics
            fig, ax = plt.subplots(figsize=(10, 6))
            
            x = np.arange(len(kernels))
            width = 0.2
            metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']
            colors = ['blue', 'green', 'red', 'purple']
            
            for i, metric in enumerate(metrics):
                values = [svm_results[kernel][metric] for kernel in kernels]
                ax.bar(x + i*width - 0.3, values, width, label=metric, color=colors[i])
            
            ax.set_xticks(x)
            ax.set_xticklabels(kernels)
            ax.set_ylabel('Score')
            ax.set_title('SVM Performance by Kernel Type')
            ax.legend()
            
            st.pyplot(fig)
            
            # Plot training times
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.bar(kernels, [training_times[k] for k in kernels], color='teal')
            ax.set_xlabel('Kernel Type')
            ax.set_ylabel('Training Time (seconds)')
            ax.set_title('SVM Training Time by Kernel')
            for i, v in enumerate([training_times[k] for k in kernels]):
                ax.text(i, v + 0.1, f"{v:.2f}s", ha='center')
            st.pyplot(fig)
            
            st.write("""
            ### SVM Kernel Explanation
            
            - **Linear Kernel**: Effective when data is linearly separable. Fast but less flexible.
            - **Polynomial Kernel**: Can model curved decision boundaries with polynomial functions.
            - **RBF (Radial Basis Function)**: Creates complex, non-linear decision boundaries. Often best for diverse data.
            - **Sigmoid Kernel**: Similar to a neural network activation function.
            For fraud detection, RBF kernel typically performs best as fraud patterns are rarely linear.
            """)

        # Add to model_tabs[1] after SVM section
        st.subheader("üìä Naive Bayes Classifier")
        
        st.write("""
        ### Naive Bayes Classification
        
        Naive Bayes is a probabilistic classifier based on Bayes' theorem with an assumption of 
        independence between features. Despite this "naive" assumption, it works surprisingly 
        well in many real-world situations, including fraud detection.
        """)
        
        run_nb = st.checkbox("Train Naive Bayes Model", value=False)
        
        if run_nb:
            from sklearn.naive_bayes import GaussianNB
            
            with st.spinner("Training Naive Bayes model..."):
                # Start timing
                start = time.time()
                
                # Create and train model
                nb_model = GaussianNB()
                nb_model.fit(X_train_resampled, y_train_resampled)
                
                # End timing
                duration = time.time() - start
                st.write(f"‚è±Ô∏è Training time: {duration:.2f} seconds")
                
                # Make predictions
                y_pred_nb = nb_model.predict(X_test)
                
                # Get probabilities
                y_proba_nb = nb_model.predict_proba(X_test)
                
                # Calculate metrics
                nb_accuracy = accuracy_score(y_test, y_pred_nb)
                nb_precision = precision_score(y_test, y_pred_nb, zero_division=0)
                nb_recall = recall_score(y_test, y_pred_nb, zero_division=0)
                nb_f1 = f1_score(y_test, y_pred_nb, zero_division=0)
                
                # Display metrics
                col1, col2 = st.columns(2)
                col1.metric("Accuracy", f"{nb_accuracy:.4f}")
                col1.metric("Precision", f"{nb_precision:.4f}")
                col2.metric("Recall", f"{nb_recall:.4f}")
                col2.metric("F1 Score", f"{nb_f1:.4f}")
                
                # Display confusion matrix
                cm_nb = confusion_matrix(y_test, y_pred_nb)
                fig, ax = plt.subplots(figsize=(6, 4))
                sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues', 
                           xticklabels=['Leg√≠tima', 'Fraude'], 
                           yticklabels=['Leg√≠tima', 'Fraude'])
                ax.set_xlabel('Previsto')
                ax.set_ylabel('Real')
                ax.set_title('Matriz de Confus√£o')
                st.pyplot(fig)
                
                # Classification report
                st.write("### Naive Bayes Classification Report")
                st.text(classification_report(y_test, y_pred_nb))
                
                # Plot probability distribution
                st.write("### Fraud Probability Distribution")
                fig, ax = plt.subplots(figsize=(10, 6))
                sns.histplot(
                    data=pd.DataFrame({
                        'Fraud Probability': y_proba_nb[:, 1],
                        'Actual Class': y_test
                    }),
                    x='Fraud Probability',
                    hue='Actual Class',
                    bins=50,
                    ax=ax
                )
                plt.axvline(x=0.5, color='red', linestyle='--', label='Default threshold (0.5)')
                plt.legend()
                st.pyplot(fig)
                
                # Add custom threshold slider
                st.write("### Custom Threshold Adjustment")
                nb_threshold = st.slider("Decision Threshold for Naive Bayes", 0.0, 1.0, 0.5, 0.01)
                
                # Apply custom threshold
                y_pred_custom_nb = (y_proba_nb[:, 1] >= nb_threshold).astype(int)
                
                # Calculate metrics with custom threshold
                custom_accuracy = accuracy_score(y_test, y_pred_custom_nb)
                custom_precision = precision_score(y_test, y_pred_custom_nb, zero_division=0)
                custom_recall = recall_score(y_test, y_pred_custom_nb, zero_division=0)
                custom_f1 = f1_score(y_test, y_pred_custom_nb, zero_division=0)
                
                # Display metrics with custom threshold
                col1, col2 = st.columns(2)
                col1.metric("Accuracy (Custom Threshold)", f"{custom_accuracy:.4f}")
                col1.metric("Precision (Custom Threshold)", f"{custom_precision:.4f}")
                col2.metric("Recall (Custom Threshold)", f"{custom_recall:.4f}")
                col2.metric("F1 Score (Custom Threshold)", f"{custom_f1:.4f}")
                
                # Display confusion matrix with custom threshold
                cm_custom_nb = confusion_matrix(y_test, y_pred_custom_nb)
                fig, ax = plt.subplots(figsize=(6, 4))
                sns.heatmap(cm_custom_nb, annot=True, fmt='d', cmap='Blues', 
                           xticklabels=['Leg√≠tima', 'Fraude'], 
                           yticklabels=['Leg√≠tima', 'Fraude'])
                ax.set_xlabel('Previsto')
                ax.set_ylabel('Real')
                ax.set_title(f'Naive Bayes Confusion Matrix (Threshold={nb_threshold:.2f})')
                st.pyplot(fig)

        # K-Nearest Neighbors (K-NN)
        st.subheader("üîé K-Nearest Neighbors (K-NN)")

        run_knn = st.checkbox("Treinar modelo K-NN", value=False)
        if run_knn:
            from sklearn.neighbors import KNeighborsClassifier

            # Sele√ß√£o do n√∫mero de vizinhos
            k_range = st.slider("Escolha o intervalo de k (n¬∫ de vizinhos)", 1, 20, (3, 10))
            k_values = list(range(k_range[0], k_range[1] + 1))
            f1_scores = []

            with st.spinner("Treinando K-NN para diferentes valores de k..."):
                for k in k_values:
                    knn = KNeighborsClassifier(n_neighbors=k)
                    knn.fit(X_train_resampled, y_train_resampled)
                    y_pred = knn.predict(X_test)
                    f1 = f1_score(y_test, y_pred, zero_division=0)
                    f1_scores.append(f1)

            # Gr√°fico F1-Score x k
            fig, ax = plt.subplots(figsize=(8, 4))
            ax.plot(k_values, f1_scores, marker='o')
            ax.set_xlabel("N√∫mero de Vizinhos (k)")
            ax.set_ylabel("F1-Score")
            ax.set_title("F1-Score para diferentes valores de k (K-NN)")
            st.pyplot(fig)

            # Melhor k
            best_k = k_values[np.argmax(f1_scores)]
            st.write(f"Melhor valor de k: **{best_k}** (F1-Score = {max(f1_scores):.4f})")

            # Avalia√ß√£o detalhada para o melhor k
            knn_best = KNeighborsClassifier(n_neighbors=best_k)
            knn_best.fit(X_train_resampled, y_train_resampled)
            y_pred_best = knn_best.predict(X_test)
            st.write("**Relat√≥rio de classifica√ß√£o (melhor k):**")
            st.text(classification_report(y_test, y_pred_best, zero_division=0))
            cm = confusion_matrix(y_test, y_pred_best, labels=[0, 1])
            fig, ax = plt.subplots(figsize=(6, 4))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['Leg√≠tima', 'Fraude'],
                        yticklabels=['Leg√≠tima', 'Fraude'])
            ax.set_xlabel('Previsto')
            ax.set_ylabel('Real')
            ax.set_title(f'Matriz de Confus√£o - K-NN (k={best_k})')
            st.pyplot(fig)

            st.write("""
            **Explica√ß√£o:**  
            O K-NN classifica uma transa√ß√£o com base nos k vizinhos mais pr√≥ximos no espa√ßo das features.  
            O valor √≥timo de k √© escolhido com base no melhor F1-Score, equilibrando precis√£o e recall para dados desbalanceados.
            """)
        st.subheader("üß† Rede Neural (MLPClassifier)")

        run_mlp = st.checkbox("Treinar Rede Neural (MLPClassifier)", value=False)
        if run_mlp:
            from sklearn.neural_network import MLPClassifier

            # Par√¢metros da rede
            hidden_layer_sizes = st.slider("Tamanho das camadas ocultas (ex: 1 camada com 20 neur√¥nios)", 5, 100, 20)
            n_layers = st.slider("N√∫mero de camadas ocultas", 1, 3, 1)
            alpha = st.slider("Alpha (regulariza√ß√£o)", 0.0001, 0.1, 0.001, step=0.0001)
            max_iter = st.slider("√âpocas de treinamento (max_iter)", 100, 1000, 300, step=50)

            # Definir arquitetura
            layers = tuple([hidden_layer_sizes] * n_layers)

            with st.spinner("Treinando a rede neural..."):
                mlp = MLPClassifier(hidden_layer_sizes=layers, alpha=alpha, max_iter=max_iter, random_state=42)
                mlp.fit(X_train_resampled, y_train_resampled)
                y_pred_mlp = mlp.predict(X_test)

            # Avalia√ß√£o
            st.write(f"Acur√°cia: {accuracy_score(y_test, y_pred_mlp):.4f}")
            st.write(f"F1-Score: {f1_score(y_test, y_pred_mlp, zero_division=0):.4f}")

            # Matriz de confus√£o
            cm = confusion_matrix(y_test, y_pred_mlp, labels=[0, 1])
            fig, ax = plt.subplots(figsize=(6, 4))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['Leg√≠tima', 'Fraude'],
                        yticklabels=['Leg√≠tima', 'Fraude'])
            ax.set_xlabel('Previsto')
            ax.set_ylabel('Real')
            ax.set_title('Matriz de Confus√£o - MLPClassifier')
            st.pyplot(fig)

            # Relat√≥rio de classifica√ß√£o
            st.write("**Relat√≥rio de classifica√ß√£o:**")
            st.text(classification_report(y_test, y_pred_mlp, zero_division=0))

            st.write("""
            **Explica√ß√£o:**  
            O MLPClassifier √© uma rede neural feedforward com camadas ocultas configur√°veis.  
            Permite capturar padr√µes complexos e n√£o lineares nos dados de fraude.
            """)

        with st.expander("üöÄ Substituto do AutoML com Random Forest"):
            st.write("""
            O Auto-Sklearn foi substitu√≠do por RandomForestClassifier para garantir compatibilidade com Python 3.8.
            Esta abordagem ainda fornece bons resultados com menor custo computacional.
            """)

            run_rf = st.checkbox("Executar Random Forest", value=False)

            if run_rf:
                with st.spinner("Treinando modelo Random Forest..."):
                    from sklearn.metrics import classification_report, accuracy_score

                    model = RandomForestClassifier(n_estimators=100, random_state=42)
                    model.fit(X_train_resampled, y_train_resampled)

                    y_pred_rf = model.predict(X_test)
                    accuracy = accuracy_score(y_test, y_pred_rf)
                    st.write(f"**Acur√°cia Random Forest:** {accuracy:.4f}")

                    st.text("Relat√≥rio de Classifica√ß√£o - Random Forest")
                    st.text(classification_report(y_test, y_pred_rf, zero_division=0))

                    st.subheader("üèÜ Import√¢ncia das Features")
                    feature_importances = pd.Series(model.feature_importances_, index=X.columns)
                    fig, ax = plt.subplots(figsize=(10, 6))
                    feature_importances.nlargest(10).plot(kind='barh', ax=ax)
                    ax.set_title("Top 10 Features mais importantes")
                    st.pyplot(fig)

    with model_tabs[2]:
        st.markdown("## Ridge e Lasso Regression para Detec√ß√£o de Fraudes")

        st.write("""
        ### Regress√£o Regularizada para Classifica√ß√£o de Fraudes

        Embora Ridge e Lasso s√£o t√©cnicas de regress√£o, elas podem ser aplicadas para problemas de classifica√ß√£o
        bin√°ria como detec√ß√£o de fraudes. Neste exemplo, usaremos essas t√©cnicas para prever a vari√°vel 'Class'
        (0: transa√ß√£o leg√≠tima, 1: transa√ß√£o fraudulenta).
        
        - **Ridge Regression**: Utiliza regulariza√ß√£o L2, que penaliza a soma dos quadrados dos coeficientes.
        - **Lasso Regression**: Utiliza regulariza√ß√£o L1, que penaliza a soma dos valores absolutos dos coeficientes e pode reduzir alguns coeficientes a zero.
        """)
        
        # Sele√ß√£o de vari√°veis
        st.subheader("Configura√ß√£o do Modelo")

        # A vari√°vel alvo agora √© fixa como "Class"
        target_column = "Class"
        st.write(f"**Vari√°vel alvo:** {target_column} (0: Leg√≠tima, 1: Fraudulenta)")
        
        n_features = st.slider("N√∫mero de features a utilizar", 2, 10, 5)
        
        # Sele√ß√£o autom√°tica de features mais correlacionadas com a vari√°vel Class
        numeric_df = df.select_dtypes(include=['number'])
        if target_column in numeric_df.columns:
            correlations = numeric_df.drop(columns=[target_column]).corrwith(df[target_column]).abs().sort_values(ascending=False)
        else:
            correlations = numeric_df.corrwith(df[target_column]).abs().sort_values(ascending=False)
        best_features = correlations[:n_features].index.tolist()
        
        st.write(f"Features selecionadas (baseadas em correla√ß√£o com {target_column}):")
        st.write(best_features)
        
        # Dividir dados
        X = df[best_features].values
        y = df[target_column].values
        
        # Normalizar dados
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Dividir em treino e teste
        test_size = st.slider("Propor√ß√£o para teste (%)", 10, 40, 20) / 100
        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, random_state=42, stratify=y)
        
        # Configura√ß√£o dos modelos
        st.subheader("Par√¢metros de Regulariza√ß√£o")
        
        col1, col2 = st.columns(2)
        with col1:
            alpha_ridge = st.slider(
                "Alpha para Ridge (for√ßa da regulariza√ß√£o L2):", 
                0.01, 10.0, 1.0, 0.01
            )
    
        with col2:
            alpha_lasso = st.slider(
                "Alpha para Lasso (for√ßa da regulariza√ß√£o L1):", 
                0.001, 1.0, 0.01, 0.001
            )
    
        # Treinamento dos modelos
        with st.spinner("Treinando modelos..."):
            # Linear Regression (sem regulariza√ß√£o)
            lr = LinearRegression()
            lr.fit(X_train, y_train)
            
            # Ridge Regression
            ridge = Ridge(alpha=alpha_ridge)
            ridge.fit(X_train, y_train)
            
            # Lasso Regression
            lasso = Lasso(alpha=alpha_lasso, max_iter=10000)
            lasso.fit(X_train, y_train)
        
        # Avalia√ß√£o dos modelos
        models = {
            "Regress√£o Linear": lr,
            f"Ridge (Œ±={alpha_ridge})": ridge,
            f"Lasso (Œ±={alpha_lasso})": lasso
        }
        
        # Configurar um limiar para converter previs√µes cont√≠nuas em bin√°rias
        threshold = 0.5
        
        results = {}
        predictions = {}
        
        for name, model in models.items():
            # Previs√µes cont√≠nuas
            y_pred_proba = model.predict(X_test)
            # Converter para bin√°rias usando threshold
            y_pred_binary = (y_pred_proba > threshold).astype(int)
            predictions[name] = y_pred_binary
            
            # M√©tricas de classifica√ß√£o
            from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
            
            accuracy = accuracy_score(y_test, y_pred_binary)
            precision = precision_score(y_test, y_pred_binary, zero_division=0)
            recall = recall_score(y_test, y_pred_binary, zero_division=0)
            f1 = f1_score(y_test, y_pred_binary, zero_division=0)
            mse = mean_squared_error(y_test, y_pred_proba)
            
            results[name] = {
                "Acur√°cia": accuracy,
                "Precis√£o": precision,
                "Recall": recall, 
                "F1-Score": f1,
                "MSE": mse
            }
        
        # Mostrar resultados
        st.subheader("Resultados dos Modelos")
        
        # Criar dataframe de resultados
        results_df = pd.DataFrame({
            model: metrics
            for model, metrics in results.items()
        }).T
        
        st.write(results_df)
        
        # Gr√°fico de barras para F1-Score (melhor m√©trica para dados desbalanceados)
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.bar(results_df.index, results_df["F1-Score"], color=["blue", "green", "orange"])
        ax.set_ylabel('F1-Score')
        ax.set_title('Compara√ß√£o de Modelos - F1-Score (maior √© melhor)')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        st.pyplot(fig)
        
        # Visualizar coeficientes
        st.subheader("Coeficientes dos Modelos")
        
        coef_df = pd.DataFrame({
            'Feature': best_features,
            'Linear Regression': lr.coef_,
            f'Ridge (Œ±={alpha_ridge})': ridge.coef_,
            f'Lasso (Œ±={alpha_lasso})': lasso.coef_
        })
        
        st.write(coef_df.set_index('Feature'))
        
        # Gr√°fico de coeficientes
        fig, ax = plt.subplots(figsize=(12, 8))
        bar_width = 0.25
        index = np.arange(len(best_features))
        
        # Plotar barras para cada modelo
        ax.bar(index - bar_width, lr.coef_, bar_width, label='Linear Regression', color='blue')
        ax.bar(index, ridge.coef_, bar_width, label=f'Ridge (Œ±={alpha_ridge})', color='green')
        ax.bar(index + bar_width, lasso.coef_, bar_width, label=f'Lasso (Œ±={alpha_lasso})', color='orange')
        
        # Adicionar linha zero para refer√™ncia
        ax.axhline(y=0, color='gray', linestyle='-', alpha=0.3)
        
        # Configurar labels e legendas
        ax.set_xlabel('Features')
        ax.set_ylabel('Coeficientes')
        ax.set_title('Import√¢ncia das Features para Detec√ß√£o de Fraudes')
        ax.set_xticks(index)
        ax.set_xticklabels(best_features, rotation=45, ha='right')
        ax.legend()
        
        plt.tight_layout()
        st.pyplot(fig)
        
        # Matriz de confus√£o para o melhor modelo
        st.subheader("Matriz de Confus√£o")
        
        # Encontrar o melhor modelo com base no F1-Score
        best_model_name = results_df["F1-Score"].idxmax()
        best_model_pred = predictions[best_model_name]
        
        cm = confusion_matrix(y_test, best_model_pred, labels=[0, 1])
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['Leg√≠tima', 'Fraude'], yticklabels=['Leg√≠tima', 'Fraude'])
        ax.set_xlabel('Previsto')
        ax.set_ylabel('Real')
        ax.set_title(f'Matriz de Confus√£o - {best_model_name}')
        st.pyplot(fig)
        
        # Explica√ß√£o sobre Ridge e Lasso para classifica√ß√£o
        st.subheader("Interpreta√ß√£o")
        
        st.write("""
        ### Aplica√ß√£o de Ridge e Lasso para Detec√ß√£o de Fraudes:
        
        1. **Interpreta√ß√£o dos Coeficientes**:
           - Coeficientes positivos: Indicam que valores maiores dessa feature aumentam a probabilidade de fraude
           - Coeficientes negativos: Indicam que valores maiores dessa feature diminuem a probabilidade de fraude
           - Coeficientes pr√≥ximos a zero (especialmente em Lasso): Indicam features menos relevantes para a detec√ß√£o
    
        2. **Compara√ß√£o dos Modelos**:
           - **Regress√£o Linear**: Sem regulariza√ß√£o, pode ser mais suscet√≠vel a overfitting, especialmente com muitas vari√°veis
           - **Ridge**: Reduz todos os coeficientes de forma proporcional, mantendo todas as features
           - **Lasso**: Tende a realizar sele√ß√£o de features, eliminando algumas completamente (coeficientes = 0)
    
        3. **Por que usar regulariza√ß√£o para fraudes?**
           - Dados de fraude geralmente t√™m muitas vari√°veis potencialmente correlacionadas
           - A regulariza√ß√£o ajuda a evitar overfitting em dados de treinamento
           - Lasso pode identificar automaticamente as vari√°veis mais importantes para detec√ß√£o
        """)
    
        # Adicionar thresholding interativo
        st.subheader("Ajuste de Limiar (Threshold)")
        
        st.write("""
        Em problemas de classifica√ß√£o desbalanceados como detec√ß√£o de fraudes, 
        ajustar o limiar de decis√£o √© crucial para equilibrar falsos positivos e falsos negativos.
        """)
        
        # Escolher um modelo para ajustar o threshold
        model_for_threshold = st.selectbox(
            "Escolha um modelo para ajustar o limiar:",
            list(models.keys())
        )
        
        # Obter as previs√µes cont√≠nuas
        selected_model = models[model_for_threshold]
        y_scores = selected_model.predict(X_test)
        
        # Slider para threshold
        custom_threshold = st.slider(
            "Limiar de decis√£o",
            min_value=0.0,
            max_value=1.0,
            value=0.5,
            step=0.01
        )
        
        # Aplicar threshold
        y_pred_custom = (y_scores > custom_threshold).astype(int)
        
        # Calcular m√©tricas com threshold personalizado
        custom_accuracy = accuracy_score(y_test, y_pred_custom)
        custom_precision = precision_score(y_test, y_pred_custom, zero_division=0)
        custom_recall = recall_score(y_test, y_pred_custom, zero_division=0)
        custom_f1 = f1_score(y_test, y_pred_custom, zero_division=0)
        
        # Exibir m√©tricas com threshold personalizado
        col1, col2 = st.columns(2)
        col1.metric("Acur√°cia", f"{custom_accuracy:.4f}")
        col1.metric("Precis√£o", f"{custom_precision:.4f}")
        col2.metric("Recall", f"{custom_recall:.4f}")
        col2.metric("F1-Score", f"{custom_f1:.4f}")
        
        # Matriz de confus√£o com threshold personalizado
        cm_custom = confusion_matrix(y_test, y_pred_custom, labels=[0, 1])
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.heatmap(cm_custom, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['Leg√≠tima', 'Fraude'], yticklabels=['Leg√≠tima', 'Fraude'])
        ax.set_xlabel('Previsto')
        ax.set_ylabel('Real')
        ax.set_title(f'Matriz de Confus√£o - {model_for_threshold} (Limiar = {custom_threshold})')
        st.pyplot(fig)