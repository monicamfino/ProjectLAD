import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import time
from sklearn.linear_model import Ridge, Lasso, LinearRegression
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.metrics import mean_squared_error, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from sklearn import tree
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier


# Configura√ß√£o da p√°gina
st.set_page_config(page_title="BugsBunny - Detec√ß√£o de Fraude üí≥", layout="wide")

# Estilizando o app
st.markdown("""
    <style>
        .big-font { font-size:30px !important; font-weight: bold; }
        .stApp { background-color: #f5f5f5; }
    </style>
""", unsafe_allow_html=True)


# Carregar os dados
@st.cache_data
def load_data():
    time.sleep(2)
    df = pd.read_csv("creditcard.csv")
    df = df.dropna()
    df["Hour"] = (df["Time"] // 3600) % 24

    # Criar novas features
    df["Rolling_Mean_Amount"] = df["Amount"].rolling(window=5).mean()
    df["Std_Amount"] = df["Amount"].rolling(window=5).std()
    df["Delta_Amount"] = df["Amount"].diff()
    df["Amount_Category"] = pd.cut(df["Amount"], bins=[0, 10, 50, 100, 500, 5000, np.inf],
                                   labels=["Very Low", "Low", "Medium", "High", "Very High", "Extreme"])
    df["Time_Diff"] = df["Time"].diff()
    df["Transacao_Noturna"] = df["Hour"].apply(lambda x: 1 if x < 6 else 0)
    df["Num_Transacoes_1h"] = df.groupby("Hour")["Time"].transform("count")
    df["Freq_Valor_Transacao"] = df.groupby("Amount")["Amount"].transform("count")
    df["Delta_Media_Valor"] = df["Amount"] - df["Rolling_Mean_Amount"]

    np.random.seed(42)
    df["Region"] = np.random.choice(["Norte", "Sul", "Leste", "Oeste", "Centro"], size=len(df))
    return df


df = load_data()

# Criar Sidebar (Menu lateral)
st.sidebar.image("https://cdn-icons-png.flaticon.com/512/1041/1041916.png", width=100)
st.sidebar.title("üê∞ BugsBunny Analytics")
st.sidebar.write("Dete√ß√£o inteligente de fraudes para proteger o seu neg√≥cio.")
page = st.sidebar.radio("Navega√ß√£o", [
    "üè† Vis√£o Geral",
    "üìä An√°lise de Fraudes",
    "üìà Estat√≠sticas",
    "üìÇ Relat√≥rios e Configura√ß√µes",
    "üß≠ Dados",
    "ü§ñ Machine Learning",
    "üß™ Classificar Transa√ß√£o"
])

# üìå P√°gina Inicial - Vis√£o Geral
if page == "üè† Vis√£o Geral":
    st.markdown('<p class="big-font">üîç Vis√£o Geral - Como identificamos fraudes</p>', unsafe_allow_html=True)

    # üè¢ Sobre a Plataforma
    st.subheader("üíº Sobre o BugsBunny Analytics")
    st.write("""
    Ajudamos empresas a identificar transa√ß√µes suspeitas com ferramentas inteligentes e f√°ceis de usar.
Combinamos tecnologia e an√°lise de dados para tornar a dete√ß√£o de fraudes mais simples e eficaz.
    """)

    # üìú Tipos Comuns de Fraude
    st.subheader("üìú Fraudes mais comuns que pode encontrar")
    fraud_types = pd.DataFrame({
        "Tipo de Fraude": ["Fraude em Cart√£o de Cr√©dito", "Phishing", "Roubo de Identidade", "Transa√ß√µes Falsificadas"],
        "Descri√ß√£o": [
            "Utiliza√ß√£o n√£o autorizada do cart√£o para compras.",
            "Enganar utilizadores para fornecerem informa√ß√µes sens√≠veis.",
            "Falsifica√ß√£o de identidade para acesso financeiro il√≠cito.",
            "Manipula√ß√£o ou falsifica√ß√£o de transa√ß√µes banc√°rias."
        ]
    })
    st.table(fraud_types)

    # üìä Estat√≠sticas Gerais
    total_transacoes = len(df)
    transacoes_fraudulentas = df["Class"].sum()
    taxa_fraude = (transacoes_fraudulentas / total_transacoes) * 100

    col1, col2, col3 = st.columns(3)
    col1.metric("üí≥ Total de Transa√ß√µes", f"{total_transacoes:,}")
    col2.metric("‚ö† Transa√ß√µes Fraudulentas", f"{transacoes_fraudulentas:,}")
    col3.metric("üìâ Taxa de Fraude", f"{taxa_fraude:.2f} %")

    # üõ†Ô∏è Vari√°veis Utilizadas no Modelo e no CSV
    st.subheader("üõ†Ô∏è Informa√ß√µes analisadas em cada transa√ß√£o")
    variaveis_combinadas = pd.DataFrame({
        "Vari√°vel": [
            "Time", "V1-V28", "Amount", "Class",
            "Hour", "Rolling_Mean_Amount", "Std_Amount", "Delta_Amount",
            "Amount_Category", "Time_Diff", "Transacao_Noturna",
            "Num_Transacoes_1h", "Freq_Valor_Transacao", "Delta_Media_Valor", "Region"
        ],
        "Descri√ß√£o": [
            "Tempo decorrido desde a primeira transa√ß√£o no dataset.",
            "Vari√°veis anonimizadas resultantes de PCA (28 componentes principais).",
            "Montante da transa√ß√£o.",
            "Classe da transa√ß√£o (0: Leg√≠tima, 1: Fraudulenta).",
            "Hora do dia em que a transa√ß√£o ocorreu.",
            "M√©dia m√≥vel do valor da transa√ß√£o (janela de 5 transa√ß√µes).",
            "Desvio padr√£o do valor da transa√ß√£o (janela de 5 transa√ß√µes).",
            "Diferen√ßa entre o valor atual e o valor anterior da transa√ß√£o.",
            "Categoria do valor da transa√ß√£o (ex.: Muito Baixo, Baixo, M√©dio, etc.).",
            "Diferen√ßa de tempo entre transa√ß√µes consecutivas.",
            "Indica se a transa√ß√£o ocorreu durante a noite (1: Sim, 0: N√£o).",
            "N√∫mero de transa√ß√µes realizadas na mesma hora.",
            "Frequ√™ncia de transa√ß√µes com o mesmo valor.",
            "Diferen√ßa entre o valor da transa√ß√£o e a m√©dia m√≥vel.",
            "Regi√£o geogr√°fica associada √† transa√ß√£o."
        ]
    })
    st.table(variaveis_combinadas)

    # üõ°Ô∏è Como Prevenir Fraudes?
    st.subheader("üõ°Ô∏è  Como pode proteger-se contra fraudes?")
    st.write("""
    Evitar fraudes √© poss√≠vel com pequenos cuidados e algumas ferramentas tecnol√≥gicas. 
    Veja abaixo as recomenda√ß√µes que mais ajudam no dia a dia.
    """)

    fraud_prevention = pd.DataFrame({
        "Tipo de Fraude": ["Fraude em Cart√£o de Cr√©dito", "Phishing", "Roubo de Identidade", "Transa√ß√µes Falsificadas"],
        "Medidas Preventivas": [
            "Ativar alertas de transa√ß√£o, usar autentica√ß√£o multifator e monitoramento cont√≠nuo.",
            "Nunca compartilhar dados pessoais, verificar remetentes suspeitos e utilizar autentica√ß√£o em dois fatores.",
            "Utilizar verifica√ß√£o biom√©trica, n√£o reutilizar senhas e ativar bloqueios autom√°ticos.",
            "Implementar monitoramento de transa√ß√µes em tempo real e an√°lises de comportamento."
        ]
    })
    st.table(fraud_prevention)

    # üí° Tecnologias e Estrat√©gias para Preven√ß√£o
    st.subheader("üí° Como a tecnologia ajuda a prevenir fraudes")
    st.write("""
   Estas s√£o algumas ferramentas usadas por empresas para manterem as suas transa√ß√µes seguras:
- **Intelig√™ncia Artificial**: Deteta padr√µes estranhos automaticamente.
- **Verifica√ß√£o em duas etapas**: Protege acessos com mais seguran√ßa.
- **Alertas em tempo real**: Detetam a√ß√µes suspeitas √† medida que acontecem.
- **Encripta√ß√£o de dados**: Mant√©m as informa√ß√µes protegidas contra roubos.
- **An√°lise de comportamento**: Identifica mudan√ßas no padr√£o de utiliza√ß√£o.
    """)

# P√°gina 2: An√°lise de Fraudes
elif page == "üìä An√°lise de Fraudes":
    st.markdown('<p class="big-font">üìä An√°lise de Fraudes</p>', unsafe_allow_html=True)
    fraud = df[df["Class"] == 1]
    legit = df[df["Class"] == 0]

    # üî• Filtros Interativos
    st.subheader("üéØ Ajustar a visualiza√ß√£o")
    hora_selecionada = st.slider("Escolha o intervalo de horas a analisar", 0, 23, (0, 23))
    regiao_selecionada = st.multiselect("Escolha as regi√µes a incluir", df["Region"].unique(), default=df["Region"].unique())

    fraude_filtrada = fraud[
        (fraud["Hour"].between(hora_selecionada[0], hora_selecionada[1])) &
        (fraud["Region"].isin(regiao_selecionada))
        ]

    # üìä Gr√°fico: Fraudes ao Longo do Dia
    st.subheader("üìÜ Em que horas ocorrem mais fraudes?")
    fig, ax = plt.subplots(figsize=(8, 4))
    sns.histplot(fraude_filtrada["Hour"], bins=24, kde=True, color="red", ax=ax)
    ax.set_xlabel("Hora do Dia")
    ax.set_ylabel("N√∫mero de Fraudes")
    st.pyplot(fig)

    # üìç Fraudes por Regi√£o
    st.subheader("üåç Onde ocorrem mais fraudes?")
    fraude_por_regiao = fraude_filtrada["Region"].value_counts(normalize=True) * 100
    fig, ax = plt.subplots(figsize=(8, 4))
    sns.barplot(x=fraude_por_regiao.index, y=fraude_por_regiao.values, palette="Reds_r", ax=ax)
    ax.set_ylabel("Percentagem de Fraudes (%)")
    st.pyplot(fig)

    # üìà Boxplot: Distribui√ß√£o dos Valores Fraudulentos
    st.subheader("üí∞Quais os valores mais comuns nas fraudes?")
    fig, ax = plt.subplots(figsize=(8, 4))
    sns.boxplot(x=fraude_filtrada["Amount"], color="red", ax=ax)
    ax.set_xlabel("Valor da Fraude ($)")
    st.pyplot(fig)

    # üìä Heatmap: Fraudes por Hora e Regi√£o
    st.subheader("üî•  Quando e onde as fraudes mais acontecem?")
    heatmap_data = fraud.pivot_table(index="Region", columns="Hour", values="Class", aggfunc="count", fill_value=0)
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.heatmap(heatmap_data, cmap="Reds", linewidths=0.5, ax=ax)
    st.pyplot(fig)

    # üìå Insights Autom√°ticos
    st.subheader("üìå O que podemos observar?")
    if len(fraude_filtrada) > 0:
        max_hora = fraude_filtrada["Hour"].value_counts().idxmax()
        max_regiao = fraude_filtrada["Region"].mode()[0]
        st.write(f"üìå **A maior concentra√ß√£o de fraudes ocorre √†s {max_hora}h.**")
        st.write(f"üìå **A regi√£o mais afetada √© {max_regiao}.**")
        st.write(f"üìå **O valor m√©dio das fraudes √© ${fraude_filtrada['Amount'].mean():.2f}.**")
        st.write(f"üìå **O maior valor de fraude registado foi ${fraude_filtrada['Amount'].max():.2f}.**")
    else:
        st.write("‚úÖ Nenhuma fraude encontrada para os filtros selecionados.")

    # üì§ Exporta√ß√£o de Dados
    st.subheader("üì• Guardar resultados filtrados")
    csv_filtros = fraude_filtrada.to_csv(index=False).encode('utf-8')
    st.download_button(label="üì• Descarregar ficheiro CSV", data=csv_filtros, file_name="fraudes_filtradas.csv", mime="text/csv")


# üìà P√°gina de Estat√≠sticas
elif page == "üìà Estat√≠sticas":
    st.markdown('<p class="big-font">üìà Estat√≠sticas das Transa√ß√µes</p>', unsafe_allow_html=True)

    st.subheader("üìä Tend√™ncia Geral das Transa√ß√µes")
    col1, col2 = st.columns(2)
    col1.write("### Valor M√©dio:")
    col1.write(df.mean(numeric_only=True))
    col2.write("### Valor Mediano:")
    col2.write(df.median(numeric_only=True))

    st.subheader("üìä Varia√ß√£o dos Valores das Transa√ß√µes")
    col1, col2 = st.columns(2)
    col1.write("### Varia√ß√£o (Vari√¢ncia):")
    col1.write(df.var(numeric_only=True))
    col2.write("### Dispers√£o (Desvio Padr√£o):")
    col2.write(df.std(numeric_only=True))

    # üî• Matriz de Correla√ß√£o
    st.subheader("üî• Liga√ß√µes entre Vari√°veis")
    fig, ax = plt.subplots(figsize=(10, 8))
    df_numeric = df.select_dtypes(include=["number"])
    sns.heatmap(df_numeric.corr(), cmap="coolwarm", annot=False, ax=ax)
    st.pyplot(fig)

    # Explica√ß√£o sobre as correla√ß√µes
    st.write("""
    üìå **O que observamos nestas liga√ß√µes:**
    - Algumas vari√°veis como a m√©dia e o desvio do valor tendem a andar juntas.
    - Certas varia√ß√µes no valor da transa√ß√£o podem indicar comportamentos menos comuns.
    """)

    # üìä Matriz de Covari√¢ncia
    st.subheader("üìä Matriz de Covari√¢ncia")
    st.write(df_numeric.cov())

    # üìå An√°lise de Fraudes por Valor e Regi√£o
    st.subheader("üí∞ Em que regi√µes ocorrem fraudes com maiores valores?")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.violinplot(data=df, x="Region", y="Amount", hue="Class", split=True, ax=ax)
    ax.set_xlabel("Regi√£o")
    ax.set_ylabel("Valor da Transa√ß√£o")
    st.pyplot(fig)

    # üìå Insights Autom√°ticos
    st.markdown("### üìå O que aprendemos com estes dados?")
    if df["Class"].sum() > 0:
        regiao_mais_fraudulenta = df[df["Class"] == 1]["Region"].mode()[0]
        valor_medio_fraude = df[df["Class"] == 1]["Amount"].mean()
        st.write(f"üìå **A regi√£o com mais fraudes √© {regiao_mais_fraudulenta}.**")
        st.write(f"üìå **O valor m√©dio de uma transa√ß√£o fraudulenta √© de R$ {valor_medio_fraude:.2f}.**")
    else:
        st.write("Nenhuma fraude detectada nos dados.")

# P√°gina 4: Relat√≥rios e Configura√ß√µes
elif page == "üìÇ Relat√≥rios e Configura√ß√µes":
    st.markdown('<p class="big-font">üìÇ Relat√≥rios e Configura√ß√µes</p>', unsafe_allow_html=True)

    # Definindo sub-p√°ginas
    sub_page = st.sidebar.radio("Subt√≥picos", ["üìë Gerar Relat√≥rio", "‚öô Configura√ß√µes Avan√ßadas", "üß™ Compara√ß√£o Visual de Vari√°veis"])

    # üìë Gera√ß√£o de Relat√≥rios Personalizados
    if sub_page == "üìë Gerar Relat√≥rio":
        st.subheader("üì• Gerar Relat√≥rio Personalizado")

        # üéØ Filtros Avan√ßados para o Relat√≥rio
        st.markdown("### üéØ Escolha o que quer incluir no seu relat√≥rio")

        # üéØ Filtros Avan√ßados para o Relat√≥rio
        colunas_disponiveis = list(df.columns)
        colunas_selecionadas = st.multiselect("Selecione os dados que pretende visualizar:", colunas_disponiveis,
                                              default=colunas_disponiveis)

        tipo_transacao = st.radio("Tipo de transa√ß√µes a incluir:", ["Todas", "Apenas Fraudes", "Apenas Leg√≠timas"])

        if tipo_transacao == "Apenas Fraudes":
            df_export = df[df["Class"] == 1]
        elif tipo_transacao == "Apenas Leg√≠timas":
            df_export = df[df["Class"] == 0]
        else:
            df_export = df.copy()

        df_export = df_export[colunas_selecionadas]

        # üìä Visualizar os dados antes do download
        st.write("üîç **Pr√©-visualiza√ß√£o das Transa√ß√µes Selecionadas:**")
        st.dataframe(df_export.head(10))

        # üìä Distribui√ß√£o de Categorias de Montante
        st.subheader("üìä  Quantidade de Transa√ß√µes por Categoria de Valor")
        fig, ax = plt.subplots(figsize=(8, 4))
        df["Amount_Category"].value_counts().plot(kind="bar", color="skyblue", ax=ax)
        ax.set_xlabel("Categoria de Valor")
        ax.set_ylabel("N√∫mero de Transa√ß√µes")
        st.pyplot(fig)

        # üåô Propor√ß√£o de Transa√ß√µes Noturnas
        st.subheader("üåô Transa√ß√µes Noturnas e Diurnas")
        transacao_noturna = df["Transacao_Noturna"].value_counts(normalize=True) * 100
        st.write(f"**Transa√ß√µes Noturnas:** {transacao_noturna[1]:.2f}%")
        st.write(f"**Transa√ß√µes Diurnas:** {transacao_noturna[0]:.2f}%")

        # üìà M√©dia M√≥vel do Montante
        st.subheader("üìà Tend√™ncia da M√©dia dos Valores")
        fig, ax = plt.subplots(figsize=(10, 5))
        df["Rolling_Mean_Amount"].plot(ax=ax, color="blue", label="M√©dia M√≥vel (√∫ltimas 5 Transa√ß√µes)")
        ax.set_xlabel("Transa√ß√µes")
        ax.set_ylabel("Valor ($)")
        ax.legend()
        st.pyplot(fig)

        # ‚è±Ô∏è Diferen√ßa de Tempo entre Transa√ß√µes
        st.subheader("‚è±Ô∏è Diferen√ßa de Tempo entre Transa√ß√µes")
        fig, ax = plt.subplots(figsize=(8, 4))
        sns.histplot(df["Time_Diff"].dropna(), bins=30, kde=True, color="purple", ax=ax)
        ax.set_xlabel("Diferen√ßa de Tempo (segundos)")
        ax.set_ylabel("Frequ√™ncia")
        st.pyplot(fig)

        # üî• Mapa de Calor: N√∫mero de Transa√ß√µes por Hora e Regi√£o
        st.subheader("üî• Mapa de Calor: N√∫mero de Transa√ß√µes por Hora e Regi√£o")
        heatmap_data = df.pivot_table(index="Region", columns="Hour", values="Num_Transacoes_1h", aggfunc="mean",
                                      fill_value=0)
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.heatmap(heatmap_data, cmap="Blues", linewidths=0.5, ax=ax)
        st.pyplot(fig)

        # üìÇ Op√ß√µes de Exporta√ß√£o
        st.markdown("### üíæ Exportar Relat√≥rio")
        formato = st.selectbox("Escolha o formato do relat√≥rio:", ["CSV", "Excel"])
        if formato == "CSV":
            file_data = df_export.to_csv(index=False).encode('utf-8')
            file_name = "relatorio_fraude.csv"
            mime_type = "text/csv"
        else:
            file_data = df_export.to_excel(index=False).encode('utf-8')
            file_name = "relatorio_fraude.xlsx"
            mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"

        st.download_button(label=f"üì• Baixar {formato}", data=file_data, file_name=file_name, mime=mime_type)

    # ‚öô Configura√ß√µes Avan√ßadas
    elif sub_page == "‚öô Configura√ß√µes Avan√ßadas":
        st.subheader("‚öô Prefer√™ncias do Sistema")

        # üìå Configura√ß√£o de Alertas de Fraude
        limite_alerta = st.slider("Definir Alerta de Transa√ß√µes Suspeitas ($):", 10, 5000, 1000)
        metodo_analise = st.radio("Escolha o m√©todo de detec√ß√£o de fraudes:", ["Regra Fixa", "Machine Learning"])

        # üåç Configura√ß√£o de Regi√µes
        st.subheader("üåé Personalizar An√°lise por Regi√£o")
        selected_region = st.multiselect("Selecione as regi√µes a monitorar:", df["Region"].unique(),
                                         default=df["Region"].unique())

        # üéØ Aplicar configura√ß√µes (Simula√ß√£o)
        if st.button("Guardar Prefer√™ncias"):
            st.success("‚úÖ Configura√ß√µes salvas com sucesso!")
            st.write(f"- **Limite de Alerta:** ${limite_alerta}")
            st.write(f"- **Tipo de verifica√ß√£o:** {metodo_analise}")
            st.write(f"- **Regi√µes monitorizadas:** {', '.join(selected_region)}")

    #  Normaliza√ß√£o e Padroniza√ß√£o
    elif sub_page == "üß™ Compara√ß√£o Visual de Vari√°veis":
        st.subheader("üß™ Compara√ß√£o Visual de Vari√°veis")

        st.write("""
        Antes de analisarmos os dados, √© importante garantir que diferentes vari√°veis estejam numa escala compar√°vel.
        üîç Esta visualiza√ß√£o permite observar como transa√ß√µes leg√≠timas e fraudulentas se distribuem em fun√ß√£o de duas vari√°veis escolhidas.

        üí° *Nota:* Algumas vari√°veis podem j√° ter sido normalizadas ou padronizadas para facilitar a compara√ß√£o visual.
        """)

        st.write("Selecione duas vari√°veis para visualizar como as transa√ß√µes leg√≠timas e fraudulentas se distribuem.")

        
        # Selecionar duas colunas para visualiza√ß√£o
        col1, col2 = st.columns(2)
        with col1:
            selected_column1 = st.selectbox("Selecione a primeira coluna:", 
                                           df.select_dtypes(include=['number']).columns,
                                           key="vis_column1")
        with col2:
            selected_column2 = st.selectbox("Selecione a segunda coluna:", 
                                           df.select_dtypes(include=['number']).columns,
                                           key="vis_column2")
        
        # Amostrar dados para evitar sobrecarga
        sample_size = min(1000, len(df))
        sample_df = df.sample(sample_size, random_state=42)
        
        # Dados originais
        fig, ax = plt.subplots(figsize=(8, 6))
        ax.scatter(sample_df[selected_column1], sample_df[selected_column2], 
                   c=sample_df['Class'], cmap='coolwarm', alpha=0.6)
        ax.set_xlabel(selected_column1)
        ax.set_ylabel(selected_column2)
        ax.set_title("Antes da Transforma√ß√£o")
        # Adicionar legenda manual
        import matplotlib.patches as mpatches
        red_patch = mpatches.Patch(color='red', label='Fraude')
        blue_patch = mpatches.Patch(color='blue', label='Leg√≠tima')
        ax.legend(handles=[red_patch, blue_patch])
        
        st.pyplot(fig)
        
        # Dados padronizados
        from sklearn.preprocessing import StandardScaler, MinMaxScaler
        
        # Preparar os dados
        X = sample_df[[selected_column1, selected_column2]].values
        y = sample_df['Class'].values
        
        # Padronizar
        scaler = StandardScaler()
        X_std = scaler.fit_transform(X)
        
        # Normalizar
        min_max_scaler = MinMaxScaler()
        X_norm = min_max_scaler.fit_transform(X)
        
        # Plotar dados padronizados
        fig, ax = plt.subplots(1, 2, figsize=(12, 5))
        
        # Padronizado
        ax[0].scatter(X_std[:, 0], X_std[:, 1], c=y, cmap='coolwarm', alpha=0.6)
        ax[0].set_xlabel(f"{selected_column1} (padronizado)")
        ax[0].set_ylabel(f"{selected_column2} (padronizado)")
        ax[0].set_title("Dados Padronizados")
        
        # Normalizado
        ax[1].scatter(X_norm[:, 0], X_norm[:, 1], c=y, cmap='coolwarm', alpha=0.6)
        ax[1].set_xlabel(f"{selected_column1} (normalizado)")
        ax[1].set_ylabel(f"{selected_column2} (normalizado)")
        ax[1].set_title("Dados Normalizados")
        
        plt.tight_layout()
        st.pyplot(fig)
        

# Nova p√°gina: Dados
elif page == "üß≠ Dados":
    st.markdown('<p class="big-font">üß≠ Dados</p>', unsafe_allow_html=True)

    st.subheader("üìä Vis√£o Geral das Transa√ß√µes")

    # Exibir as vari√°veis e seus valores
    variaveis_valores = {
        "Total de Transa√ß√µes": len(df),
        "Transa√ß√µes Fraudulentas": df["Class"].sum(),
        "Taxa de Fraude (%)": (df["Class"].sum() / len(df)) * 100,
        "Valor M√©dio das Transa√ß√µes ($)": df["Amount"].mean(),
        "Valor M√°ximo das Transa√ß√µes ($)": df["Amount"].max(),
        "Valor M√≠nimo das Transa√ß√µes ($)": df["Amount"].min(),
        "Desvio Padr√£o do Valor das Transa√ß√µes ($)": df["Amount"].std()
    }

    for variavel, valor in variaveis_valores.items():
        st.metric(label=variavel, value=f"{valor:,.2f}" if isinstance(valor, float) else f"{valor:,}")

    # Adicionar scope das vari√°veis
    st.subheader("üìÑ Descri√ß√£o das Vari√°veis")

    variaveis_escopo = {
        "Time": "Tempo decorrido desde a primeira transa√ß√£o no dataset.",
        "Vx": "Vari√°veis anonimizadas resultantes de PCA (28 componentes principais).",
        "Amount": "Montante da transa√ß√£o.",
        "Class": "Classe da transa√ß√£o (0: Leg√≠tima, 1: Fraudulenta).",
        "Hour": "Hora do dia em que a transa√ß√£o ocorreu.",
        "Rolling_Mean_Amount": "M√©dia m√≥vel do valor da transa√ß√£o (janela de 5 transa√ß√µes).",
        "Std_Amount": "Desvio padr√£o do valor da transa√ß√£o (janela de 5 transa√ß√µes).",
        "Delta_Amount": "Diferen√ßa entre o valor atual e o valor anterior da transa√ß√£o.",
        "Amount_Category": "Categoria do valor da transa√ß√£o (ex.: Muito Baixo, Baixo, M√©dio, etc.).",
        "Time_Diff": "Diferen√ßa de tempo entre transa√ß√µes consecutivas.",
        "Transacao_Noturna": "Indica se a transa√ß√£o ocorreu durante a noite (1: Sim, 0: N√£o).",
        "Num_Transacoes_1h": "N√∫mero de transa√ß√µes realizadas na mesma hora.",
        "Freq_Valor_Transacao": "Frequ√™ncia de transa√ß√µes com o mesmo valor.",
        "Delta_Media_Valor": "Diferen√ßa entre o valor da transa√ß√£o e a m√©dia m√≥vel.",
        "Region": "Regi√£o geogr√°fica associada √† transa√ß√£o."
    }

    for variavel, descricao in variaveis_escopo.items():
        st.write(f"**{variavel}:** {descricao}")

    # Adicionar gr√°ficos de valores m√≠nimo e m√°ximo
    st.subheader("üìä Comparativo de Valores M√≠nimos e M√°ximos")

    # Agregar dados de V1-V28 em Vx
    df["Vx"] = df[[f"V{i}" for i in range(1, 29)]].sum(axis=1)
    min_vals = df[["Vx", "Hour", "Time_Diff"]].min()
    max_vals = df[["Vx", "Hour", "Time_Diff"]].max()

    fig, ax = plt.subplots(figsize=(12, 6))
    ax.bar(min_vals.index, min_vals.values, color="blue", label="Min")
    ax.bar(max_vals.index, max_vals.values, color="red", label="Max", alpha=0.7)
    ax.set_title("Valores M√≠nimo e M√°ximo de Vx, Hour e Time_Diff")
    ax.set_ylabel("Valores")
    ax.legend()
    plt.xticks(rotation=90)
    st.pyplot(fig)

    # Adicionar gr√°ficos de valores m√≠nimo e m√°ximo
    st.subheader("üìä Amplitude das Outras Vari√°veis Num√©ricas")

    # Remover colunas indesejadas
    columns_to_exclude = [f"V{i}" for i in range(1, 29)] + ["Vx", "Hour", "Time_Diff", "Class", "Transacao_Noturna"]
    numeric_columns = df.select_dtypes(include=['number']).columns
    numeric_columns = [col for col in numeric_columns if col not in columns_to_exclude]

    # Calcular valores m√≠nimos e m√°ximos apenas para colunas num√©ricas filtradas
    min_vals = df[numeric_columns].min()
    max_vals = df[numeric_columns].max()

    # Garantir que os √≠ndices sejam strings
    min_vals.index = min_vals.index.astype(str)
    max_vals.index = max_vals.index.astype(str)

    # Garantir que os valores sejam num√©ricos
    min_vals = pd.to_numeric(min_vals, errors='coerce').fillna(0)
    max_vals = pd.to_numeric(max_vals, errors='coerce').fillna(0)

    # Criar o gr√°fico
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.bar(min_vals.index, min_vals.values, color="blue", label="Min")
    ax.bar(max_vals.index, max_vals.values, color="red", label="Max", alpha=0.7)
    ax.set_title("Valores M√≠nimo e M√°ximo das Vari√°veis Num√©ricas")
    ax.set_ylabel("Valores")
    ax.legend()
    plt.xticks(rotation=90)
    st.pyplot(fig)

    # Adicionar legenda explicativa
    st.markdown("""
    **Legenda:**
    - **Min**: Valor mais baixo registado para a vari√°vel.
    - **Max**:  Valor mais alto registado para a vari√°vel.
    Estes indicadores ajudam a perceber a varia√ß√£o e o alcance dos dados analisados.
    """)

# Nova p√°gina: Machine Learning
elif page == "ü§ñ Machine Learning":
    # Adicionar tabs para diferentes modelos de ML
    model_tabs = st.tabs(["Introdu√ß√£o", "Classifica√ß√£o", "Ridge e Lasso Regression"])
    
    with model_tabs[0]:
        # Mover o conte√∫do existente sobre ML para esta tab
        st.markdown("## Introdu√ß√£o ao Machine Learning")
        
        # Conceitos b√°sicos
        st.subheader("üîç O que √© Machine Learning?")
        st.write("""
        O Machine Learning permite que os computadores **reconhe√ßam padr√µes automaticamente** a partir de dados ‚Äî sem precisarmos dizer exatamente o que fazer em cada situa√ß√£o.
        
        Em vez de programar regras fixas, o sistema **aprende com exemplos anteriores** para prever ou tomar decis√µes em situa√ß√µes futuras.
        """)
        
        # Compara√ß√£o visual entre programa√ß√£o tradicional e ML
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### üíª Programa√ß√£o Tradicional")
            st.markdown("""
            ```
            Dados + Regras ‚Üí Resultados
            ```
            """)
            st.write("As regras s√£o definidas pelo programador")
            
        with col2:
            st.markdown("### ü§ñ Machine Learning")
            st.markdown("""
            ```
            Dados + Resultados ‚Üí Regras
            ```
            """)
            st.write("As regras s√£o descobertas pelo algoritmo")
        
        # Tipos de aprendizado
        st.subheader("üìö Tipos de Aprendizagens")
        
        tab1, tab2, tab3 = st.tabs(["Supervisionado", "N√£o Supervisionado", "Por Refor√ßo"])
        
        with tab1:
            st.markdown("### Aprendizagem Supervisionado")
            st.write("""
            Neste tipo de aprendizagem, o sistema **aprende com exemplos que j√° t√™m a resposta certa**. 
            Assim, pode depois aplicar esse conhecimento para prever novos casos.

            **Exemplos:**
            - Identificar e-mails como spam ou n√£o spam
            - Prever o valor de uma casa
            - Distinguir transa√ß√µes leg√≠timas de fraudulentas
            """)
            
            # Demonstra√ß√£o visual simples
            st.markdown("üñºÔ∏è Exemplo Visual: Transa√ß√µes Leg√≠timas vs Fraudulentas")
            
            fig, ax = plt.subplots(figsize=(6, 4))
            
            # Amostra pequena para demonstra√ß√£o
            sample = df.sample(100, random_state=42)
            ax.scatter(sample["Amount"], sample["V1"], c=sample["Class"], cmap="coolwarm", s=50)
            ax.set_xlabel("Valor da Transa√ß√£o")
            ax.set_ylabel("Componente V1")
            ax.set_title("Classifica√ß√£o de Transa√ß√µes")
            
            # Adicionar legenda manual
            import matplotlib.patches as mpatches
            red_patch = mpatches.Patch(color='red', label='Fraude')
            blue_patch = mpatches.Patch(color='blue', label='Leg√≠tima')
            ax.legend(handles=[red_patch, blue_patch])
            
            st.pyplot(fig)
        
        with tab2:
            st.markdown("### Aprendizagem N√£o Supervisionado")
            st.write("""
            Neste caso, o sistema **n√£o sabe as respostas certas**. Ele tenta encontrar **agrupamentos ou padr√µes escondidos** nos dados por conta pr√≥pria.

            **Exemplos:**
            - Agrupar clientes com perfis semelhantes
            - Identificar padr√µes incomuns
            """)
            
            # Demonstra√ß√£o visual de clustering
            st.markdown(" üñºÔ∏è Exemplo Visual: Agrupamento de Transa√ß√µes")
            
            from sklearn.cluster import KMeans
            
            # Amostra para demonstra√ß√£o
            sample = df.sample(200, random_state=42)
            X = sample[["Amount", "V1"]].values
            
            # Aplicar K-means
            kmeans = KMeans(n_clusters=3, random_state=42)
            sample_clusters = kmeans.fit_predict(X)
            
            # Visualizar
            fig, ax = plt.subplots(figsize=(6, 4))
            scatter = ax.scatter(X[:, 0], X[:, 1], c=sample_clusters, cmap="viridis", s=50)
            ax.set_xlabel("Valor da Transa√ß√£o")
            ax.set_ylabel("Componente V1")
            ax.set_title("Agrupamento de Transa√ß√µes (K-means)")
            
            # Adicionar centr√≥ides
            ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], 
                      marker='X', s=200, color='red', label='Centr√≥ides')
            ax.legend()
            
            st.pyplot(fig)
        
        with tab3:
            st.markdown(" Aprendizagem por Refor√ßo")
            st.write("""
            Aqui, o sistema **aprende por tentativa e erro**. Ele testa a√ß√µes e **recebe recompensas ou penaliza√ß√µes** com base no que acontece. Com o tempo, aprende quais decis√µes levam aos melhores resultados.
            """)
            
            st.image("https://cdn-images-1.medium.com/max/800/1*Z2yMvuRTXcMHRdHzKMRM5w.png", 
                    caption="Ciclo de Aprendizado por Refor√ßo", width=400)
    
        # Processo de Machine Learning
        st.subheader("‚öôÔ∏è Processo de Machine Learning")
    
        process_steps = {
             "1. Prepara√ß√£o de Dados": "Recolha, limpeza, normaliza√ß√£o e divis√£o em conjuntos de treinamento/teste",
             "2. Sele√ß√£o de Modelo": "Escolha do algoritmo mais adequado para o problema",
             "3. Treinamento": "Ajuste dos par√¢metros do modelo usando dados de treinamento",
             "4. Valida√ß√£o": "Avalia√ß√£o do desempenho em dados n√£o vistos anteriormente",
             "5. Otimiza√ß√£o": "Melhoria do modelo ajustando as suas configura√ß√µes",
             "6. Implementa√ß√£o": "Coloca√ß√£o do modelo em produ√ß√£o",
             "7. Monitoriza√ß√£o": "Acompanhamento cont√≠nuo do desempenho"
          }
    
        col1, col2 = st.columns(2)
    
        for i, (step, desc) in enumerate(process_steps.items()):
           if i < 4:
              col1.markdown(f"**{step}:** {desc}")
           else:
              col2.markdown(f"**{step}:** {desc}")
    
         # Aplica√ß√µes em detec√ß√£o de fraudee
        st.subheader("üí≥ Como o Machine Learning Ajuda a Detetar Fraudes")
    
        st.write("""
          A dete√ß√£o de fraudes √© uma das aplica√ß√µes mais valiosas do machine learning no setor financeiro. 
          Estes modelos conseguem identificar comportamentos suspeitos que muitas vezes escapam √† an√°lise humana.

          **Vantagens:**
          - ‚ö° An√°lise em tempo real
          - üìà Capacidade de adapta√ß√£o a novos tipos de fraude
          - üéØ Redu√ß√£o de falsos alarmes
          - üß† Processamento de grandes volumes de transa√ß√µes

         **Desafios:**
          - ‚öñÔ∏è Poucas fraudes em compara√ß√£o com transa√ß√µes normais (desequil√≠brio nos dados)
          - üïµÔ∏è‚Äç‚ôÇÔ∏è Novas formas de fraude surgem constantemente
          - ‚è±Ô∏è Necessidade de decis√µes r√°pidas
          - üîê Prote√ß√£o dos dados dos clientes
        """)
    
        # M√©tricas de avalia√ß√£o
        st.subheader("üìè Como Avaliamos se um Modelo √© Bom?")
    
        metrics = {
         "Accuracy": "Percentagem total de previs√µes corretas",
         "Precis√£o": "Entre os casos classificados como fraude, quantos realmente s√£o fraude",
         "Recall (Sensibilidade)": "Entre as fraudes reais, quantas foram detectadas corretamente",
         "F1-Score": "Equil√≠brio entre precis√£o e recall",
         "AUC-ROC": "Capacidade de distinguir entre classes (0.5 = aleat√≥rio, 1.0 = perfeito)",
         "Custo de erros": "Impacto financeiro de uma dete√ß√£o incorreta"
        }
    
        for metric, desc in metrics.items():
          st.markdown(f"**{metric}**: {desc}")
    
        # Demonstra√ß√£o pr√°tica
        st.subheader("üß™ Exemplo Simples de Detec√ß√£o de Fraudes")
    

        st.write("""
          Abaixo mostramos uma simula√ß√£o de como um modelo pode aprender a distinguir fraudes de transa√ß√µes leg√≠timas.

         ‚ö†Ô∏è Este √© apenas um exemplo simples, com poucas vari√°veis, usado apenas para fins educativos.
         """)
        
        from sklearn.model_selection import train_test_split
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
        
        # Preparar dados (amostra pequena para demonstra√ß√£o r√°pida)
        sample = df.sample(1000, random_state=42)
        X = sample[["Amount", "V1", "V3", "V4"]].values
        y = sample["Class"].values
        
        # Dividir em treino e teste
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
        
        # Vers√£o mais robusta para o treinamento com SMOTE
        with st.spinner('Treinando o modelo...'):
            model = RandomForestClassifier(n_estimators=10, random_state=42)
            
            # Verificar se h√° amostras suficientes para aplicar SMOTE
            try:
                # Verificar o n√∫mero m√≠nimo de amostras nas classes
                class_counts = np.bincount(y_train)
                min_class_count = class_counts.min()
                
                # Decidir qual m√©todo usar com base no n√∫mero de amostras
                if min_class_count >= 6:  # Para k=5 o SMOTE precisa de pelo menos 6 amostras por classe
                    # SMOTE regular
                    smote = SMOTE(random_state=42)
                    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
                elif min_class_count >= 2:  # Se tiver ao menos 2 amostras, usar k=1
                    st.warning("Poucas amostras na classe minorit√°ria. Usando SMOTE com k=1.")
                    smote = SMOTE(k_neighbors=1, random_state=42)
                    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
                else:
                    # Se mesmo assim n√£o for poss√≠vel, usar os dados originais
                    st.warning("Dados muito desbalanceados. Usando dados originais sem SMOTE.")
                    X_train_resampled, y_train_resampled = X_train, y_train
            except Exception as e:
                # Capturar qualquer erro do SMOTE
                st.error(f"Erro ao aplicar SMOTE: {str(e)}. Usando dados originais.")
                X_train_resampled, y_train_resampled = X_train, y_train
        
        # Treinar o modelo com os dados processados
        model.fit(X_train_resampled, y_train_resampled)
        
        # Fazer previs√µes
        y_pred = model.predict(X_test)
        
        # Avaliar modelo
        st.write("**Accuracy do modelo:**", accuracy_score(y_test, y_pred))
        
        # Matriz de confus√£o
        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])  # Especificamos explicitamente as classes 0 e 1
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['Leg√≠tima', 'Fraude'], yticklabels=['Leg√≠tima', 'Fraude'])
        ax.set_xlabel('Previsto')
        ax.set_ylabel('Real')
        ax.set_title('Matriz de Confus√£o')
        st.pyplot(fig)
        
        # Relat√≥rio de classifica√ß√£o
        st.write("**Relat√≥rio de classifica√ß√£o:**")
        st.text(classification_report(y_test, y_pred, zero_division=0))
        
        # Import√¢ncia das features
        importances = model.feature_importances_
        feature_names = ["Amount", "V1", "V3", "V4"]
        
        fig, ax = plt.subplots(figsize=(6, 4))
        ax.bar(feature_names, importances)
        ax.set_ylabel('Import√¢ncia')
        ax.set_title('Import√¢ncia das Features')
        st.pyplot(fig)
        
        st.write("""
         üìå **Nota:** Este exemplo foi simplificado para melhor compreens√£o. 
         Em situa√ß√µes reais, s√£o utilizados muitos mais dados e t√©cnicas para garantir uma dete√ß√£o mais precisa e justa.
        """)
    
    with model_tabs[1]:
        # Mover a demonstra√ß√£o de classifica√ß√£o para esta tab
        st.markdown("##  üïµÔ∏è‚Äç‚ôÇÔ∏è Classifica√ß√£o para Identificar Fraudes")
        
        # Carregar dados
        df = pd.read_csv("creditcard.csv")
        df = df.dropna()
        
        # Criar vari√°vel alvo (Class) desbalanceada
        df["Class"] = df["Class"].astype("category")
        
        # Amostra dos dados
        st.subheader("üîç Exemplo de Transa√ß√µes")
        st.write("Aqui est√° uma amostra aleat√≥ria dos dados utilizados na an√°lise:")
        st.write(df.sample(10))
        
        # Contagem das classes
        st.subheader("üìä Quantas fraudes temos?")
        class_counts = df["Class"].value_counts()
        st.bar_chart(class_counts)
        
        # Sele√ß√£o de vari√°veis
        st.subheader("üß© Quais vari√°veis vamos usar?")
        
        all_columns = df.columns.tolist()
        target = "Class"
        features = st.multiselect(
            "Escolha os dados que o modelo deve usar para aprender:",
            options=all_columns,
            default=all_columns[:-1]  # Selecionar todas menos a √∫ltima (que √© a vari√°vel alvo)
        )
        
        # Garantir que a vari√°vel alvo n√£o esteja entre as features selecionadas
        if target in features:
            features.remove(target)
        
        st.write("‚úÖ Vari√°veis selecionadas:", features)
        
        # Dividir dados
        X = df[features]
        y = df[target]
        
        # Dividir em treino e teste
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
        
        # Treinamento do modelo
        st.subheader("‚öôÔ∏è Escolha o modelo de classifica√ß√£o")
        
        # Selecionar modelo
        model_type = st.selectbox(
            "Modelo:",
            ["Random Forest", "Regress√£o Log√≠stica", "√Årvore de Decis√£o"]
        )

        if model_type == "Random Forest":
            from sklearn import tree

            st.subheader("üå≥ Visualiza√ß√£o de uma √Årvore Individual do Random Forest")
            tree_idx = st.slider("Escolha o √≠ndice da √°rvore para visualizar", 0, len(model.estimators_) - 1, 0)
            fig, ax = plt.subplots(figsize=(16, 6))
            tree.plot_tree(
                model.estimators_[tree_idx],
                feature_names=features,
                class_names=["Leg√≠tima", "Fraude"],
                filled=True,
                rounded=True,
                max_depth=3,  # Limite para facilitar a visualiza√ß√£o
                fontsize=10,
                ax=ax
            )
            st.pyplot(fig)
            st.write(f"**√Årvore exibida:** Estimador {tree_idx} do Random Forest (apenas os 3 primeiros n√≠veis).")
        elif model_type == "Regress√£o Log√≠stica":
            from sklearn.linear_model import LogisticRegression
            model = LogisticRegression(class_weight='balanced', solver='liblinear', max_iter=2000, random_state=42)
        else:
            if model_type == "√Årvore de Decis√£o":
                from sklearn import tree

                st.subheader("üå≥ Visualiza√ß√£o da √Årvore")

                # Se o modelo for uma RandomForest, escolher uma das √°rvores
                if isinstance(model, RandomForestClassifier):
                    st.warning("Est√°s a visualizar uma √°rvore individual de uma Random Forest.")
                    tree_idx = st.slider("Escolhe o √≠ndice da √°rvore a visualizar", 0, len(model.estimators_) - 1, 0)
                    tree_to_plot = model.estimators_[tree_idx]
                else:
                    tree_to_plot = model  # Assume que √© DecisionTreeClassifier

                fig, ax = plt.subplots(figsize=(16, 6))
                tree.plot_tree(
                    tree_to_plot,
                    feature_names=features,
                    class_names=["Leg√≠tima", "Fraude"],
                    filled=True,
                    rounded=True,
                    max_depth=3,
                    fontsize=10,
                    ax=ax
                )
                st.pyplot(fig)
                st.write("**Nota:** Apenas os 3 primeiros n√≠veis da √°rvore est√£o vis√≠veis para facilitar a leitura.")

                # An√°lise do √≠ndice Gini
                st.subheader("üìä An√°lise do √çndice Gini dos N√≥s da √Årvore")
                gini_values = tree_to_plot.tree_.impurity
                node_samples = tree_to_plot.tree_.n_node_samples
                gini_df = pd.DataFrame({
                    "N√≥": range(len(gini_values)),
                    "√çndice Gini": gini_values,
                    "Amostras no N√≥": node_samples
                })
                st.write(gini_df.head(10))  # Mostra os 10 primeiros n√≥s

                fig, ax = plt.subplots(figsize=(8, 4))
                ax.plot(gini_df["N√≥"], gini_df["√çndice Gini"], marker="o")
                ax.set_xlabel("N√≥")
                ax.set_ylabel("√çndice Gini")
                ax.set_title("√çndice Gini ao longo dos n√≥s da √°rvore")
                st.pyplot(fig)

                st.write("""
                **O √≠ndice Gini mede a impureza dos n√≥s:**
                - Valor 0: n√≥ puro (todas as amostras da mesma classe)
                - Valor pr√≥ximo de 0.5: mistura equilibrada das classes
                """)
        
        # Treinar modelo
        with st.spinner(f'Treinando o modelo ({model_type})...'):
            # Aplicar SMOTE para balancear as classes
            smote = SMOTE(random_state=42)
            X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
            
            model.fit(X_train_resampled, y_train_resampled)

            # Defina o n√∫mero de componentes do PCA
            n_components = st.slider("N¬∫ de componentes do PCA", 2, min(len(features), 20), 5)

            # Treinamento SEM PCA
            start = time.time()
            model_no_pca = RandomForestClassifier(n_estimators=50, random_state=42)
            model_no_pca.fit(X_train, y_train)
            fit_time_no_pca = time.time() - start
            acc_no_pca = model_no_pca.score(X_test, y_test)

            # Treinamento COM PCA
            pca = PCA(n_components=n_components, random_state=42)
            X_train_pca = pca.fit_transform(X_train)
            X_test_pca = pca.transform(X_test)

            start = time.time()
            model_pca = RandomForestClassifier(n_estimators=50, random_state=42)
            model_pca.fit(X_train_pca, y_train)
            fit_time_pca = time.time() - start
            acc_pca = model_pca.score(X_test_pca, y_test)

            # Exibir resultados
            st.subheader("Compara√ß√£o: Com vs. Sem PCA")
            results = pd.DataFrame({
                "Accuracy": [acc_no_pca, acc_pca],
                "Tempo de ajuste (s)": [fit_time_no_pca, fit_time_pca]
            }, index=["Sem PCA", "Com PCA"])
            st.write(results)
        
        # Avalia√ß√£o do modelo
        st.subheader("Avalia√ß√£o do Modelo")


        # Fazer previs√µes
        y_pred = model.predict(X_test)
        
        # Accuracy
        accuracy = accuracy_score(y_test, y_pred)
        st.write(f"Accuracy: {accuracy:.2f}")
        
        # Matriz de confus√£o
        st.subheader("Matriz de Confus√£o")
        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])  # Especificamos explicitamente as classes 0 e 1
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['Leg√≠tima', 'Fraude'], yticklabels=['Leg√≠tima', 'Fraude'])
        ax.set_xlabel('Previsto')
        ax.set_ylabel('Real')
        ax.set_title('Matriz de Confus√£o')
        st.pyplot(fig)
        
        # Relat√≥rio de classifica√ß√£o
        st.write("**Relat√≥rio de classifica√ß√£o:**")
        st.text(classification_report(y_test, y_pred, zero_division=0))
        
        # Import√¢ncia das features (apenas para Random Forest)
        if model_type == "Random Forest":
            st.subheader("Import√¢ncia das Features")
            
            importances = model.feature_importances_
            feature_names = features
            
            # Criar dataframe de import√¢ncias
            importance_df = pd.DataFrame({
                'Feature': feature_names,
                'Import√¢ncia': importances
            }).sort_values(by="Import√¢ncia", ascending=False)
            
            st.write(importance_df)
            
            # Gr√°fico de barras
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.barplot(data=importance_df, x="Import√¢ncia", y="Feature", ax=ax, hue="Import√¢ncia", palette="viridis", legend=False)
            ax.set_title("Import√¢ncia das Features - Random Forest")
            ax.set_xlabel("Features")
            ax.set_ylabel("Import√¢ncia")
            st.pyplot(fig)

        # Add to model_tabs[1] after the existing classification models
        st.subheader("üöÄ Testar Modelos Avan√ßados")

        st.write("""
       ### Experimente diferentes modelos para detetar poss√≠veis fraudes

       Aqui pode comparar os resultados de dois m√©todos populares que analisam padr√µes nos dados. Basta ativar e ajustar os par√¢metros desejados.
        """)

        # Create columns for the two models
        col1, col2 = st.columns(2)

        with col1:
            st.write("#### AdaBoost")

            run_ada = st.checkbox("Ativar AdaBoost", value=False)
            if run_ada:
                from sklearn.ensemble import AdaBoostClassifier

                # Set parameters
                n_estimators = st.slider("N√∫mero de estimadores (AdaBoost)", 50, 300, 100)
                learning_rate = st.slider("Taxa de aprendizagem (AdaBoost)", 0.01, 2.0, 1.0, 0.01)

                with st.spinner("A treinar modelo..."):
                    # Start timing
                    start = time.time()

                    # Create and train model
                    ada_model = AdaBoostClassifier(
                        n_estimators=n_estimators,
                        learning_rate=learning_rate,
                        random_state=42
                    )
                    ada_model.fit(X_train_resampled, y_train_resampled)

                    # End timing
                    duration = time.time() - start
                    st.write(f"‚è±Ô∏è Training time: {duration:.2f} seconds")

                    # Make predictions
                    y_pred_ada = ada_model.predict(X_test)

                    # Calculate metrics
                    ada_accuracy = accuracy_score(y_test, y_pred_ada)
                    ada_precision = precision_score(y_test, y_pred_ada, zero_division=0)
                    ada_recall = recall_score(y_test, y_pred_ada, zero_division=0)
                    ada_f1 = f1_score(y_test, y_pred_ada, zero_division=0)

                    # Display metrics
                    st.metric("Accuracy", f"{ada_accuracy:.4f}")
                    st.metric("Precis√£o", f"{ada_precision:.4f}")
                    st.metric("Recall", f"{ada_recall:.4f}")
                    st.metric("F1 Score", f"{ada_f1:.4f}")

                    # Display confusion matrix
                    cm_ada = confusion_matrix(y_test, y_pred_ada)
                    fig, ax = plt.subplots(figsize=(5, 4))
                    sns.heatmap(cm_ada, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['Leg√≠tima', 'Fraude'], yticklabels=['Leg√≠tima', 'Fraude'])
                    ax.set_xlabel('Previsto')
                    ax.set_ylabel('Real')
                    ax.set_title('Matriz de Confus√£o - AdaBoost')
                    st.pyplot(fig)

        with col2:
            st.write("#### XGBoost")

            run_xgb = st.checkbox("Ativar XGBoost", value=False)
            if run_xgb:
                import xgboost as xgb

                # Set parameters
                n_estimators_xgb = st.slider("N√∫mero de estimadores (XGBoost)", 50, 300, 100)
                max_depth = st.slider("Profundidade m√°xima (XGBoost)", 3, 10, 6)
                learning_rate_xgb = st.slider("Taxa de aprendizagem (XGBoost)", 0.01, 0.3, 0.1, 0.01)

                with st.spinner("A treinar modelo..."):
                    # Start timing
                    start = time.time()

                    # Create and train model
                    xgb_model = xgb.XGBClassifier(
                        n_estimators=n_estimators_xgb,
                        max_depth=max_depth,
                        learning_rate=learning_rate_xgb,
                        random_state=42
                    )
                    xgb_model.fit(X_train_resampled, y_train_resampled)

                    # End timing
                    duration = time.time() - start
                    st.write(f"‚è±Ô∏è Tempo de treino: {duration:.2f} segundos")

                    # Make predictions
                    y_pred_xgb = xgb_model.predict(X_test)

                    # Calculate metrics
                    xgb_accuracy = accuracy_score(y_test, y_pred_xgb)
                    xgb_precision = precision_score(y_test, y_pred_xgb, zero_division=0)
                    xgb_recall = recall_score(y_test, y_pred_xgb, zero_division=0)
                    xgb_f1 = f1_score(y_test, y_pred_xgb, zero_division=0)

                    # Display metrics
                    st.metric("Accuracy", f"{xgb_accuracy:.4f}")
                    st.metric("Precis√£o", f"{xgb_precision:.4f}")
                    st.metric("Recall", f"{xgb_recall:.4f}")
                    st.metric("F1 Score", f"{xgb_f1:.4f}")

                    # Display confusion matrix
                    cm_xgb = confusion_matrix(y_test, y_pred_xgb)
                    fig, ax = plt.subplots(figsize=(5, 4))
                    sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['Leg√≠tima', 'Fraude'], yticklabels=['Leg√≠tima', 'Fraude'])
                    ax.set_xlabel('Previsto')
                    ax.set_ylabel('Real')
                    ax.set_title('Matriz de Confus√£o - XGBoost')
                    st.pyplot(fig)

                    # Feature importance for XGBoost
                    fig, ax = plt.subplots(figsize=(8, 6))
                    xgb.plot_importance(xgb_model, ax=ax, max_num_features=10)
                    plt.title("XGBoost Feature Importance")
                    st.pyplot(fig)

        # Compare boosting models if both have been trained
        if run_ada and run_xgb:
            st.subheader("üìä Compara√ß√£o entre AdaBoost e XGBoost")

            # Create comparison dataframe
            boost_comparison = pd.DataFrame({
                'Modelo': ['AdaBoost', 'XGBoost'],
                'Accuracy': [ada_accuracy, xgb_accuracy],
                'Precis√£o': [ada_precision, xgb_precision],
                'Recall': [ada_recall, xgb_recall],
                'F1 Score': [ada_f1, xgb_f1]
            })

            st.write(boost_comparison)

            # Plot comparison
            fig, ax = plt.subplots(figsize=(10, 6))

            x = np.arange(2)
            width = 0.2
            metrics = ['Accuracy', 'Precis√£o', 'Recall', 'F1 Score']
            colors = ['blue', 'green', 'red', 'purple']

            for i, metric in enumerate(metrics):
                values = boost_comparison[metric].values
                ax.bar(x + i*width - 0.3, values, width, label=metric, color=colors[i])

            ax.set_xticks(x)
            ax.set_xticklabels(boost_comparison['Modelo'])
            ax.set_ylabel('Valor')
            ax.set_title('Compara√ß√£o dos Modelos Boosting')
            ax.legend()

            st.pyplot(fig)

        # Add to model_tabs[1] after boosting methods
        st.subheader("üîÑ Avaliar Modelos com SVM")

        st.write("""
        Pode tamb√©m experimentar outro tipo de modelo para comparar resultados. Aqui √© poss√≠vel testar diferentes vers√µes (chamadas **kernels**) e ver qual funciona melhor com os dados.
        """)

        run_svm = st.checkbox("Testar modelos SVM", value=False)

        if run_svm:
            from sklearn.svm import SVC

            # Kernels to test
            kernels = ["linear", "poly", "rbf", "sigmoid"]

            # Create dictionary to store results
            svm_results = {}
            training_times = {}

            with st.spinner("A treinar modelos SVM com diferentes configura√ß√µes..."):
                for kernel in kernels:
                    # Start timing
                    start = time.time()

                    # Create and train model
                    svm_model = SVC(
                        kernel=kernel,
                        probability=True,
                        random_state=42,
                        class_weight='balanced'
                    )

                    # Fit model
                    svm_model.fit(X_train_resampled, y_train_resampled)

                    # End timing
                    duration = time.time() - start
                    training_times[kernel] = duration

                    # Make predictions
                    y_pred_svm = svm_model.predict(X_test)

                    # Calculate metrics
                    svm_accuracy = accuracy_score(y_test, y_pred_svm)
                    svm_precision = precision_score(y_test, y_pred_svm, zero_division=0)
                    svm_recall = recall_score(y_test, y_pred_svm, zero_division=0)
                    svm_f1 = f1_score(y_test, y_pred_svm, zero_division=0)

                    # Store results
                    svm_results[kernel] = {
                        'Accuracy': svm_accuracy,
                        'Precis√£o': svm_precision,
                        'Recall': svm_recall,
                        'F1 Score': svm_f1,
                        'Tempo de Treino': duration
                    }

            # Display results as table
            st.subheader("üìä Resultados dos Modelos SVM")
            st.write("Aqui pode ver o desempenho dos diferentes tipos de SVM testados:")
            svm_df = pd.DataFrame.from_dict(svm_results, orient='index')
            st.write(svm_df)
            
            # Find best kernel
            best_kernel = svm_df['F1 Score'].idxmax()
            st.write(f"üü¢ Melhor desempenho (F1 Score): **{best_kernel}**")
            
            # Plot performance metrics
            fig, ax = plt.subplots(figsize=(10, 6))
            
            x = np.arange(len(kernels))
            width = 0.2
            metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']
            colors = ['blue', 'green', 'red', 'purple']
            
            for i, metric in enumerate(metrics):
                values = [svm_results[kernel][metric] for kernel in kernels]
                ax.bar(x + i*width - 0.3, values, width, label=metric, color=colors[i])
            
            ax.set_xticks(x)
            ax.set_xticklabels(kernels)
            ax.set_ylabel('Valor')
            ax.set_title('Compara√ß√£o dos Modelos SVM por Tipo')
            ax.legend()
            
            st.pyplot(fig)
            
            # Plot training times
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.bar(kernels, [training_times[k] for k in kernels], color='teal')
            ax.set_xlabel('Tipo de Kernel')
            ax.set_ylabel('Tempo de Treino (segundos)')
            ax.set_title('Tempo de Treino por Tipo de SVM')
            for i, v in enumerate([training_times[k] for k in kernels]):
                ax.text(i, v + 0.1, f"{v:.2f}s", ha='center')
            st.pyplot(fig)


        # Add to model_tabs[1] after SVM section
        st.subheader("üìä Modelo Naive Bayes")
        run_nb = st.checkbox("Testar Modelo Naive Bayes", value=False)
        
        if run_nb:
            from sklearn.naive_bayes import GaussianNB
            
            with st.spinner("A treinar modelo..."):
                # Start timing
                start = time.time()
                
                # Create and train model
                nb_model = GaussianNB()
                nb_model.fit(X_train_resampled, y_train_resampled)
                
                # End timing
                duration = time.time() - start
                st.write(f"‚è±Ô∏è Tempo de treino: {duration:.2f} segundos")
                
                # Make predictions
                y_pred_nb = nb_model.predict(X_test)
                
                # Get probabilities
                y_proba_nb = nb_model.predict_proba(X_test)
                
                # Calculate metrics
                nb_accuracy = accuracy_score(y_test, y_pred_nb)
                nb_precision = precision_score(y_test, y_pred_nb, zero_division=0)
                nb_recall = recall_score(y_test, y_pred_nb, zero_division=0)
                nb_f1 = f1_score(y_test, y_pred_nb, zero_division=0)
                
                # Display metrics
                col1, col2 = st.columns(2)
                col1.metric("Accuracy", f"{nb_accuracy:.4f}")
                col1.metric("Precis√£o", f"{nb_precision:.4f}")
                col2.metric("Recall", f"{nb_recall:.4f}")
                col2.metric("F1 Score", f"{nb_f1:.4f}")
                
                # Display confusion matrix
                cm_nb = confusion_matrix(y_test, y_pred_nb)
                fig, ax = plt.subplots(figsize=(6, 4))
                sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues', 
                           xticklabels=['Leg√≠tima', 'Fraude'], 
                           yticklabels=['Leg√≠tima', 'Fraude'])
                ax.set_xlabel('Previsto')
                ax.set_ylabel('Real')
                ax.set_title('Matriz de Confus√£o - Naive Bayes')
                st.pyplot(fig)
                
                # Classification report
                st.write("### Naive Bayes Classification Report")
                st.text(classification_report(y_test, y_pred_nb))
                
                # Plot probability distribution
                st.write("### Distribui√ß√£o de Probabilidades de Fraude")
                fig, ax = plt.subplots(figsize=(10, 6))
                sns.histplot(
                    data=pd.DataFrame({
                        'Probabilidade de Fraude': y_proba_nb[:, 1],
                        'Classe Real': y_test
                    }),
                    x='Probabilidade de Fraude',
                    hue='Classe Real',
                    bins=50,
                    ax=ax
                )
                plt.axvline(x=0.5, color='red', linestyle='--', label='Default threshold (0.5)')
                plt.legend()
                st.pyplot(fig)
                
                # Add custom threshold slider
                st.write("### Ajustar Limiar de Decis√£o")
                nb_threshold = st.slider("Limiar (threshold)", 0.0, 1.0, 0.5, 0.01)
                
                # Apply custom threshold
                y_pred_custom_nb = (y_proba_nb[:, 1] >= nb_threshold).astype(int)
                
                # Calculate metrics with custom threshold
                custom_accuracy = accuracy_score(y_test, y_pred_custom_nb)
                custom_precision = precision_score(y_test, y_pred_custom_nb, zero_division=0)
                custom_recall = recall_score(y_test, y_pred_custom_nb, zero_division=0)
                custom_f1 = f1_score(y_test, y_pred_custom_nb, zero_division=0)
                
                # Display metrics with custom threshold
                col1, col2 = st.columns(2)
                col1.metric("Accuracy (Limiar)", f"{custom_accuracy:.4f}")
                col1.metric("Precis√£o (Limiar)", f"{custom_precision:.4f}")
                col2.metric("Recall (Limiar)", f"{custom_recall:.4f}")
                col2.metric("F1 Score (Limiar)", f"{custom_f1:.4f}")
                
                # Display confusion matrix with custom threshold
                cm_custom_nb = confusion_matrix(y_test, y_pred_custom_nb)
                fig, ax = plt.subplots(figsize=(6, 4))
                sns.heatmap(cm_custom_nb, annot=True, fmt='d', cmap='Blues', 
                           xticklabels=['Leg√≠tima', 'Fraude'], 
                           yticklabels=['Leg√≠tima', 'Fraude'])
                ax.set_xlabel('Previsto')
                ax.set_ylabel('Real')
                ax.set_title(f'Matriz de Confus√£o - Limiar{nb_threshold:.2f}')
                st.pyplot(fig)

        # K-Nearest Neighbors (K-NN)
        st.subheader("üîé K-Nearest Neighbors (K-NN)")

        run_knn = st.checkbox("Treinar modelo K-NN", value=False)
        if run_knn:
            from sklearn.neighbors import KNeighborsClassifier

            # Sele√ß√£o do n√∫mero de vizinhos
            k_range = st.slider("Escolha o intervalo de k (n¬∫ de vizinhos)", 1, 20, (3, 10))
            k_values = list(range(k_range[0], k_range[1] + 1))
            f1_scores = []

            with st.spinner("A treinar modelos para diferentes valores de k..."):
                for k in k_values:
                    knn = KNeighborsClassifier(n_neighbors=k)
                    knn.fit(X_train_resampled, y_train_resampled)
                    y_pred = knn.predict(X_test)
                    f1 = f1_score(y_test, y_pred, zero_division=0)
                    f1_scores.append(f1)

            # Gr√°fico F1-Score x k
            fig, ax = plt.subplots(figsize=(8, 4))
            ax.plot(k_values, f1_scores, marker='o')
            ax.set_xlabel("N√∫mero de Vizinhos (k)")
            ax.set_ylabel("F1-Score")
            ax.set_title("Desempenho do K-NN")
            st.pyplot(fig)

            # Melhor k
            best_k = k_values[np.argmax(f1_scores)]
            st.write(f"Melhor valor k encontrado: **{best_k}** (F1-Score = {max(f1_scores):.4f})")

            # Avalia√ß√£o detalhada para o melhor k
            knn_best = KNeighborsClassifier(n_neighbors=best_k)
            knn_best.fit(X_train_resampled, y_train_resampled)
            y_pred_best = knn_best.predict(X_test)
            st.write("**Relat√≥rio de classifica√ß√£o (melhor k):**")
            st.text(classification_report(y_test, y_pred_best, zero_division=0))
            cm = confusion_matrix(y_test, y_pred_best, labels=[0, 1])
            fig, ax = plt.subplots(figsize=(6, 4))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['Leg√≠tima', 'Fraude'],
                        yticklabels=['Leg√≠tima', 'Fraude'])
            ax.set_xlabel('Previsto')
            ax.set_ylabel('Real')
            ax.set_title(f'Matriz de Confus√£o - K-NN (k={best_k})')
            st.pyplot(fig)

        st.subheader("üß† Rede Neural (MLPClassifier)")

        run_mlp = st.checkbox("Treinar Rede Neural", value=False)
        if run_mlp:
            from sklearn.neural_network import MLPClassifier

            # Par√¢metros da rede
            hidden_layer_sizes = st.slider("Neur√≥nios por camada", 5, 100, 20)
            n_layers = st.slider("N√∫mero de camadas ocultas", 1, 3, 1)
            alpha = st.slider("Alpha (regulariza√ß√£o)", 0.0001, 0.1, 0.001, step=0.0001)
            max_iter = st.slider("√âpocas de treinamento (max_iter)", 100, 1000, 300, step=50)

            # Definir arquitetura
            layers = tuple([hidden_layer_sizes] * n_layers)

            with st.spinner("A treinar a rede neural..."):
                mlp = MLPClassifier(hidden_layer_sizes=layers, alpha=alpha, max_iter=max_iter, random_state=42)
                mlp.fit(X_train_resampled, y_train_resampled)
                y_pred_mlp = mlp.predict(X_test)

            # Avalia√ß√£o
            st.write(f"Accuracy: {accuracy_score(y_test, y_pred_mlp):.4f}")
            st.write(f"F1-Score: {f1_score(y_test, y_pred_mlp, zero_division=0):.4f}")

            # Matriz de confus√£o
            cm = confusion_matrix(y_test, y_pred_mlp, labels=[0, 1])
            fig, ax = plt.subplots(figsize=(6, 4))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['Leg√≠tima', 'Fraude'],
                        yticklabels=['Leg√≠tima', 'Fraude'])
            ax.set_xlabel('Previsto')
            ax.set_ylabel('Real')
            ax.set_title('Matriz de Confus√£o - MLPClassifier')
            st.pyplot(fig)

            # Relat√≥rio de classifica√ß√£o
            st.write("**Relat√≥rio de classifica√ß√£o:**")
            st.text(classification_report(y_test, y_pred_mlp, zero_division=0))


        with st.expander("üöÄ Random Forest (substituto ao AutoML)"):
            st.info("Modelo alternativo ao AutoML, compat√≠vel com a vers√£o usada.")

            run_rf = st.checkbox("Executar Random Forest", value=False)

            if run_rf:
                with st.spinner("A treinar modelo Random Forest..."):
                    from sklearn.metrics import classification_report, accuracy_score

                    model = RandomForestClassifier(n_estimators=100, random_state=42)
                    model.fit(X_train_resampled, y_train_resampled)

                    y_pred_rf = model.predict(X_test)
                    accuracy = accuracy_score(y_test, y_pred_rf)
                    st.write(f"**Accuracy Random Forest:** {accuracy:.4f}")

                    st.text("Relat√≥rio de Classifica√ß√£o - Random Forest")
                    st.text(classification_report(y_test, y_pred_rf, zero_division=0))

                    st.subheader("üèÜ Import√¢ncia das Features")
                    feature_importances = pd.Series(model.feature_importances_, index=X.columns)
                    fig, ax = plt.subplots(figsize=(10, 6))
                    feature_importances.nlargest(10).plot(kind='barh', ax=ax)
                    ax.set_title("Top 10 Features mais importantes")
                    st.pyplot(fig)

    with model_tabs[2]:
        st.markdown("## üîç An√°lise com Ridge e Lasso")

        st.write("""
       Vamos explorar diferentes formas de prever se uma transa√ß√£o √© fraudulenta ou n√£o.  
    Os modelos apresentados utilizam combina√ß√µes de vari√°veis para fazer essa previs√£o, ajudando-nos a compreender quais s√£o mais relevantes.
        """)
        
        # Sele√ß√£o de vari√°veis
        st.subheader("‚öôÔ∏è Configura√ß√µes Iniciais")

        # A vari√°vel alvo agora √© fixa como "Class"
        target_column = "Class"
        st.write(f"**Vari√°vel alvo:** {target_column} (0: Leg√≠tima, 1: Fraudulenta)")
        
        n_features = st.slider("N√∫mero de features a utilizar", 2, 10, 5)
        
        # Sele√ß√£o autom√°tica de features mais correlacionadas com a vari√°vel Class
        numeric_df = df.select_dtypes(include=['number'])
        if target_column in numeric_df.columns:
            correlations = numeric_df.drop(columns=[target_column]).corrwith(df[target_column]).abs().sort_values(ascending=False)
        else:
            correlations = numeric_df.corrwith(df[target_column]).abs().sort_values(ascending=False)
        best_features = correlations[:n_features].index.tolist()
        
        st.write(f"Vari√°veis selecionadas (mais associadas com fraudes {target_column}):")
        st.write(best_features)
        
        # Dividir dados
        X = df[best_features].values
        y = df[target_column].values
        
        # Normalizar dados
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Dividir em treino e teste
        test_size = st.slider("Percentagem de dados para teste", 10, 40, 20) / 100
        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, random_state=42, stratify=y)
        
        # Configura√ß√£o dos modelos
        st.subheader("üîß Par√¢metros dos Modelos")
        
        col1, col2 = st.columns(2)
        with col1:
            alpha_ridge = st.slider(
                "Ajuste do modelo Ridge",
                0.01, 10.0, 1.0, 0.01
            )
    
        with col2:
            alpha_lasso = st.slider(
                "Ajuste do modelo Lasso",
                0.001, 1.0, 0.01, 0.001
            )
    
        # Treinamento dos modelos
        with st.spinner("A treinar modelos..."):
            # Linear Regression (sem regulariza√ß√£o)
            lr = LinearRegression()
            lr.fit(X_train, y_train)
            
            # Ridge Regression
            ridge = Ridge(alpha=alpha_ridge)
            ridge.fit(X_train, y_train)
            
            # Lasso Regression
            lasso = Lasso(alpha=alpha_lasso, max_iter=10000)
            lasso.fit(X_train, y_train)
        
        # Avalia√ß√£o dos modelos
        models = {
            "Regress√£o Linear": lr,
            f"Ridge (Œ±={alpha_ridge})": ridge,
            f"Lasso (Œ±={alpha_lasso})": lasso
        }
        
        # Configurar um limiar para converter previs√µes cont√≠nuas em bin√°rias
        threshold = 0.5
        
        results = {}
        predictions = {}
        
        for name, model in models.items():
            # Previs√µes cont√≠nuas
            y_pred_proba = model.predict(X_test)
            # Converter para bin√°rias usando threshold
            y_pred_binary = (y_pred_proba > threshold).astype(int)
            predictions[name] = y_pred_binary
            
            # M√©tricas de classifica√ß√£o
            from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
            
            accuracy = accuracy_score(y_test, y_pred_binary)
            precision = precision_score(y_test, y_pred_binary, zero_division=0)
            recall = recall_score(y_test, y_pred_binary, zero_division=0)
            f1 = f1_score(y_test, y_pred_binary, zero_division=0)
            mse = mean_squared_error(y_test, y_pred_proba)
            
            results[name] = {
                "Accuracy": accuracy,
                "Precis√£o": precision,
                "Recall": recall, 
                "F1-Score": f1,
                "Erro M√©dio (MSE)": mse
            }
        
        # Mostrar resultados
        st.subheader("üìä Compara√ß√£o dos Resultados")
        
        # Criar dataframe de resultados
        results_df = pd.DataFrame({
            model: metrics
            for model, metrics in results.items()
        }).T
        
        st.write(results_df)
        
        # Gr√°fico de barras para F1-Score (melhor m√©trica para dados desbalanceados)
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.bar(results_df.index, results_df["F1-Score"], color=["blue", "green", "orange"])
        ax.set_ylabel('F1-Score por Modelo')
        ax.set_title('F1-Score (quanto maior, melhor)')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        st.pyplot(fig)
        
        # Visualizar coeficientes
        st.subheader("üìå Relev√¢ncia das Vari√°veis")
        
        coef_df = pd.DataFrame({
            'Vari√°vel': best_features,
            'Linear Regression': lr.coef_,
            f'Ridge (Œ±={alpha_ridge})': ridge.coef_,
            f'Lasso (Œ±={alpha_lasso})': lasso.coef_
        })
        
        st.write(coef_df.set_index('Vari√°vel'))
        
        # Gr√°fico de coeficientes
        fig, ax = plt.subplots(figsize=(12, 8))
        bar_width = 0.25
        index = np.arange(len(best_features))
        
        # Plotar barras para cada modelo
        ax.bar(index - bar_width, lr.coef_, bar_width, label='Linear Regression', color='blue')
        ax.bar(index, ridge.coef_, bar_width, label=f'Ridge (Œ±={alpha_ridge})', color='green')
        ax.bar(index + bar_width, lasso.coef_, bar_width, label=f'Lasso (Œ±={alpha_lasso})', color='orange')
        
        # Adicionar linha zero para refer√™ncia
        ax.axhline(y=0, color='gray', linestyle='-', alpha=0.3)
        
        # Configurar labels e legendas
        ax.set_xlabel('Vari√°vel')
        ax.set_ylabel('Coeficientes')
        ax.set_title('Import√¢ncia das Vari√°vel para Detec√ß√£o de Fraudes')
        ax.set_xticks(index)
        ax.set_xticklabels(best_features, rotation=45, ha='right')
        ax.legend()
        
        plt.tight_layout()
        st.pyplot(fig)

    
        # Adicionar thresholding interativo
        st.subheader("üéØ Ajuste de Sensibilidade (Threshold)")
        
        st.write("""
        Pode ajustar a sensibilidade da decis√£o do modelo.  
    Um valor mais baixo pode detetar mais fraudes (mas com mais falsos positivos),  
    enquanto um valor mais alto √© mais cauteloso.
        """)
        
        # Escolher um modelo para ajustar o threshold
        model_for_threshold = st.selectbox(
            "Escolha um modelo para ajustar o limiar:",
            list(models.keys())
        )
        
        # Obter as previs√µes cont√≠nuas
        selected_model = models[model_for_threshold]
        y_scores = selected_model.predict(X_test)
        
        # Slider para threshold
        custom_threshold = st.slider(
            "Limiar de decis√£o",
            min_value=0.0,
            max_value=1.0,
            value=0.5,
            step=0.01
        )
        
        # Aplicar threshold
        y_pred_custom = (y_scores > custom_threshold).astype(int)
        
        # Calcular m√©tricas com threshold personalizado
        custom_accuracy = accuracy_score(y_test, y_pred_custom)
        custom_precision = precision_score(y_test, y_pred_custom, zero_division=0)
        custom_recall = recall_score(y_test, y_pred_custom, zero_division=0)
        custom_f1 = f1_score(y_test, y_pred_custom, zero_division=0)
        
        # Exibir m√©tricas com threshold personalizado
        col1, col2 = st.columns(2)
        col1.metric("Accuracy", f"{custom_accuracy:.4f}")
        col1.metric("Precis√£o", f"{custom_precision:.4f}")
        col2.metric("Recall", f"{custom_recall:.4f}")
        col2.metric("F1-Score", f"{custom_f1:.4f}")
        
        # Matriz de confus√£o com threshold personalizado
        cm_custom = confusion_matrix(y_test, y_pred_custom, labels=[0, 1])
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.heatmap(cm_custom, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=['Leg√≠tima', 'Fraude'], yticklabels=['Leg√≠tima', 'Fraude'])
        ax.set_xlabel('Previsto')
        ax.set_ylabel('Real')
        ax.set_title(f'Matriz de Confus√£o - {model_for_threshold} (Limiar = {custom_threshold})')
        st.pyplot(fig)

elif page == "üß™ Classificar Transa√ß√£o":
    st.markdown('<p class="big-font">üß™ Classificar Transa√ß√£o</p>', unsafe_allow_html=True)
    st.write(" Introduza os dados de uma nova transa√ß√£o para saber se ela poder√° ser considerada suspeita. O sistema analisa os valores com base em padr√µes reais j√° observados em transa√ß√µes anteriores.")

    # Features usadas no modelo
    selected_features = ["Amount", "V1", "V2", "V3", "V4", "V10"]

    # Inputs do utilizador
    input_data = {}
    for feature in selected_features:
        input_data[feature] = st.number_input(f"Insera valor para: {feature}", value=0.0)

    # Criar DataFrame a partir dos inputs
    input_df = pd.DataFrame([input_data])

    # Preparar os dados de treino
    X = df[selected_features]
    y = df["Class"]

    # Normalizar com StandardScaler
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Treinar modelo de regress√£o log√≠stica
    from sklearn.linear_model import LogisticRegression
    model = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42)
    model.fit(X_scaled, y)

    # Transformar input do utilizador
    input_scaled = scaler.transform(input_df)

    # Prever probabilidade de fraude
    prob_fraude = model.predict_proba(input_scaled)[0][1]

    st.write(f"üîç **Probabilidade de ser fraude:** {prob_fraude:.4f}")

    # Definir limiar
    limiar = 0.5
    if prob_fraude > limiar:
        st.error("üö® Transa√ß√£o suspeita de fraude!")
    else:
        st.success("‚úÖ Transa√ß√£o leg√≠tima.")
